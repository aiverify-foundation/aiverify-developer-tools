{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AI Verify Developer Documentation","text":"<p>AI Verify is built with extensibility and open source collaboration in mind. Adopting a modular software design approach, it is powered by a plugin system, where features ranging from report templates to testing algorithms can be customised and enhanced through an AI Verify plugin. In the spirit of open source, AI Verify welcomes developers and interested parties to collaborate together and get started here.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>We encourage everyone to contribute to AI Verify and that\u2019s why we have put up this developer\u2019s guide. If you still have questions after reading the material, please take a look at the Contributing Guidelines.</p> <p>For first time contributors, we hope you find the following guide from Open Source Guides useful:</p> <ul> <li>How to Contribute to Open Source</li> </ul>"},{"location":"#bugs","title":"Bugs","text":"<p>If you come across a bug with our API or want to report incorrect documentation, please open an issue on our issue tracker.</p>"},{"location":"getting_started/install_aiverify_dev_tools/","title":"Installing AI Verify Developer Tools","text":""},{"location":"getting_started/install_aiverify_dev_tools/#before-you-begin","title":"Before You Begin","text":"<p>This page prepares your environment for development on AI Verify. By the end of this guided example, you should end up with the following folder structure.</p> <pre><code>&lt;working directory&gt;/\n\u251c\u2500\u2500 aiverify/\n    \u251c\u2500\u2500 aiverify-shared-library/\n    \u251c\u2500\u2500 common/\n\u251c\u2500\u2500 aiverify-developer-tools/\n    \u251c\u2500\u2500 README.md\n    \u251c\u2500\u2500 aiverify-algorithm-template/\n    \u251c\u2500\u2500 aiverify-plugin/\n    \u2514\u2500\u2500 template_plugin/\n\u251c\u2500\u2500 my_plugin/\n\u2514\u2500\u2500 .venv/\n</code></pre>"},{"location":"getting_started/install_aiverify_dev_tools/#step-1-installing-dependencies","title":"Step 1. Installing Dependencies","text":"<p>Install the following dependencies if they are not already available.</p>"},{"location":"getting_started/install_aiverify_dev_tools/#installation-on-ubuntu-22","title":"Installation on Ubuntu 22","text":"<p>Install jq and zip</p> <pre><code>sudo apt update\nsudo apt-get install -y jq zip\n</code></pre> <p>Install Python 3.11</p> <pre><code>sudo add-apt-repository ppa:deadsnakes/ppa\nsudo apt update\nsudo apt install python3.11\n</code></pre> <p>Install NodeJS</p> <pre><code>curl -fsSL https://deb.nodesource.com/setup_22.x | sudo -E bash -\nsudo apt-get install -y nodejs\n</code></pre>"},{"location":"getting_started/install_aiverify_dev_tools/#installation-on-macos","title":"Installation on MacOS","text":"<p>The following steps assume homebrew is installed.</p> <p>Install jq and zip</p> <pre><code>brew install jq zip\n</code></pre> <p>Install Python 3.11</p> <pre><code>brew install python@3.11\n</code></pre> <p>Install NodeJS <pre><code>brew install node@22\n</code></pre></p>"},{"location":"getting_started/install_aiverify_dev_tools/#step-2-preparing-a-virtual-environment","title":"Step 2. Preparing a Virtual Environment","text":"<p>We recommend setting up a virtual environment for your plugin project to ensure that these libraries will not mess up your main development environment.</p> <p>Step 1. Create and activate a python virtual environment <pre><code># Execute in the working directory\npython3 -m venv .venv\nsource .venv/bin/activate\nwhich python # you should see something like &lt;working directory&gt;/.venv/bin/python\n</code></pre></p> <p>Step 2. Install plugin dependencies in your virtual environment <pre><code>pip install --upgrade pip\npip install cookiecutter pytest 'aiverify-test-engine[all]'\n</code></pre></p>"},{"location":"getting_started/install_aiverify_dev_tools/#step-3-install-the-required-modules-from-ai-verify-repository","title":"Step 3. Install the required modules from AI Verify repository","text":"<p>The Developer Tools require specific modules from the main AI Verify repository. If you have not installed AI Verify, use sparse-checkout on the AI Verify repository to selectively checkout files that are relevant to the Developer Tools.</p> <p>Sparse checkout the required modules for AI Verify repository.</p> <pre><code># Execute in the working directory\ngit clone --no-checkout git@github.com:aiverify-foundation/aiverify.git\ncd aiverify\ngit sparse-checkout init --cone\ngit sparse-checkout set aiverify-shared-library common\nls # You should be able to see the three folders\ngit checkout main </code></pre> <p>After the sparse checkout, you should end up with these two folders in your <code>aiverify</code> project directory.</p> <pre><code>&lt;working directory&gt;/\n\u251c\u2500\u2500 aiverify/\n    \u251c\u2500\u2500 aiverify-shared-library/\n    \u251c\u2500\u2500 common/\n</code></pre> <p>Install the require modules.</p> <pre><code>cd aiverify-shared-library\nnpm install\nnpm run build\ncd ../.. # back to working directory\n</code></pre>"},{"location":"getting_started/install_aiverify_dev_tools/#step-4-install-the-ai-verify-developer-tool","title":"Step 4. Install the AI Verify Developer Tool","text":"<p>Clone our developer's repository. You should clone this in the same directory you cloned aiverify.</p> <pre><code># Execute in the working directory\ngit clone https://github.com/IMDA-BTG/aiverify-developer-tools.git\n</code></pre> <p>Install AI Verify Developer Tools in your environment.</p> <pre><code>cd aiverify-developer-tools/aiverify-plugin\nnpm install\nnpm link ../../aiverify/ai-verify-shared-library\nsudo npm install -g # You may need sudo for this command\n</code></pre> <p>If the installation is successful, you should see a similar output as shown below.</p>"},{"location":"getting_started/install_aiverify_dev_tools/#aiverify-plugin","title":"aiverify-plugin","text":"<pre><code>$ aiverify-plugin --help\naiverify-plugin &lt;cmd&gt; [args]\n\nCommands:\n  aiverify-plugin generate-plugin [gid]      Generate skeleton AI Verify plugin project                  [aliases: gp]\n  aiverify-plugin generate-widget &lt;cid&gt;      Generate skeleton AI Verify widget                          [aliases: gw]\n  aiverify-plugin generate-inputblock &lt;cid&gt;  Generate skeleton AI Verify input block                    [aliases: gib]\n  aiverify-plugin generate-algorithm &lt;cid&gt;   Generate skeleton AI Verify algorithm                       [aliases: ga]\n  aiverify-plugin zip [pluginDir]            Create the plugin zip file\n  aiverify-plugin validate                   Validate AI Verify plugin\n  aiverify-plugin test-widget                Run the plugin tests for widgets and input blocks        [aliases: testw]\n  aiverify-plugin test-algorithm             Run the plugin tests for algorithms                      [aliases: testa]\n  aiverify-plugin test-all                   Run all the tests for widgets, input blocks and algorithms with default\n                                              options\n  aiverify-plugin playground                 Launch the plugin playround\n\nOptions:\n  --help  Show help                                                                                           [boolean]\n</code></pre> <p>Congratulations! You are ready to create your first plugin.</p>"},{"location":"getting_started/start_here/","title":"Getting Started","text":"<p>The developer guide is designed to be beginner-friendly for developers, but assumes some familiarity and proficiency in Python, Javascript, and MDX.</p>"},{"location":"getting_started/start_here/#learning-objectives","title":"Learning Objectives","text":"<p>You will learn to:</p> <ol> <li>Install AI Verify Developer Tools</li> <li>Introduction to AI Verify Plugins</li> <li>Create an algorithm component that will return the values of a selected feature of your test dataset</li> <li>Create an widget component that will print out the output from the algorithm component</li> <li>Package algorithm and widget components into a single deployable plugin</li> <li>Debugging workflow other avenues to seek help</li> </ol>"},{"location":"getting_started/start_here/#system-requirements","title":"System Requirements","text":"<p>To start developing on AI Verify, you will need to install AI Verify Developer Tools. These are the minimum requirements to run AI Verify on a local computer:</p> <ul> <li>OS Requirements: Ubuntu 22 (64-bit) or MacOS</li> <li>Disk Space: &gt;= 3GB disk space</li> <li>RAM: &gt;= 4GB memory</li> </ul> <p>Warning</p> <p>We do not officially provide support for Windows. For Windows developers, AI Verify requires minimally Windows 10 with WSL2. Please note that we have not conducted tests on Windows 10. Please follow instructions to set up WSL2 here if you still wish to proceed.</p>"},{"location":"getting_started/start_here/#installing-ai-verify-developer-tools","title":"Installing AI Verify Developer Tools","text":"<p>Upon installing AI Verify, please proceed with the installation of the Developer Tools.</p>"},{"location":"getting_started/start_here/#building-your-first-ai-verify-plugin","title":"Building your first AI Verify plugin","text":"<p>In this tutorial, you will learn about the fundamental concepts to build a plugin. This guide will walk you through building your first AI Verify plugin using both Javascript and Python, and by the end you will have a working plugin that can be loaded on AI Verify to run an algorithm and generate a simple report.</p>"},{"location":"guided_example/deploy_your_plugin/","title":"Deploy Your Plugin","text":"<p>Now that you have created your plugin component(s), it is time to package it into a single plugin for deployment.</p> <p>If you are following the guided example, you should have the following components completed and packaged in its own respective folders:</p> <ol> <li>my_algorithm component</li> <li>my_inputblock component</li> <li>my_widget component</li> </ol>"},{"location":"guided_example/deploy_your_plugin/#combine-the-plugin-components","title":"Combine the plugin components","text":"<p>The my_plugin directory should mimic the same plugin structure. The <code>algorithms</code> directory should contain algorithms, with each one in its own respective folder. The widget components will be stored in the <code>widgets</code> directory and input blocks will be stored in the <code>inputs</code> directory..</p> <p></p>"},{"location":"guided_example/deploy_your_plugin/#edit-plugin-details-optional","title":"Edit Plugin Details (Optional)","text":"<p>You may wish to edit plugin.meta.json to change the plugin details.</p> plugin.meta.json<pre><code>{\n\"gid\": \"my_plugin\",\n\"name\": \"My Plugin\",\n\"version\": \"1.0.0\",\n\"description\": \"My First Plugin\",\n\"author\": \"AI Verify\"\n}\n</code></pre>"},{"location":"guided_example/deploy_your_plugin/#deploy-your-plugin_1","title":"Deploy your Plugin","text":"<p>You can package your plugin using the <code>aiverify-plugin zip</code> command.</p> <pre><code># Execute this command under the my_plugin directory\naiverify-plugin zip\n</code></pre> <p>Note</p> <p>A new folder <code>dist</code> will be created. This folder is where the packaged <code>.zip</code> file will be created and placed.</p> <p>Verify that the zip file <code>my_plugin-1.0.0.zip</code> exists in your <code>dist</code> directory:</p> <p>The resulting plugin is packaged as a <code>zip</code> file, which can be used to share with other developers who are interested in using your plugin. Users and developers can then upload the zip file onto AI Verify through the plugin manager and use it in the report.</p>"},{"location":"guided_example/deploy_your_plugin/#uploading-the-plugin","title":"Uploading the plugin","text":"<p>To upload the plugin, start the frontend portal of AI Verify. You will need to install AI Verify if you have not done so. The instructions to install and run AI Verify from source code can be found in the User Guide.</p> <ol> <li> <p>Once the portal is started up, visit the portal at http://localhost:3000/home. In the homepage, click on Manage -&gt; Plugins to visit the Plugin Manager page:     </p> </li> <li> <p>In the Plugin Manager page, click on \"UPLOAD PLUGIN\" at the top right. Then either drag and drop <code>my_plugin-0.1.0.zip</code> to the file selector or click to browse and select the zip file. Then click \"CONFIRM UPLOAD\" to upload the plugin:     </p> </li> <li> <p>The following prompt should appear to inform you that the plugin has been installed successfully:      </p> </li> <li> <p>Click the back arrow key to return to the Plugin Manager page. You should see your plugin in the list of installed plugins:     </p> </li> </ol>"},{"location":"guided_example/deploy_your_plugin/#upload-the-test-datasets-and-models","title":"Upload the Test Datasets and Models","text":"<p>Select and upload the dataset, ground truth dataset and model. You can download the test dataset and model from the AI Verify Github Repository. </p> <ol> <li> <p>From the Homepage, select Manage -&gt; Models page and then click the UPLOAD MODEL button.</p> </li> <li> <p>Select the Upload AI Model to upload a model file and click \"Next\".    </p> </li> <li> <p>Drag and drop <code>sample_bc_credit_sklearn_linear.LogisticRegression.sav</code> to the upload file selector, or click to browse and select the file. The filename <code>sample_bc_credit_sklearn_linear.LogisticRegression.sav</code> should appear on the selected file list. Select <code>Classification</code> next to the file name and click UPLOAD FILES(S) to upload the file.    </p> </li> <li> <p>Once the file has been uploaded, click the back arrow <code>&lt;-</code> twice to return the model list page. You should now see the uploaded model appear in the list.    </p> </li> <li> <p>From the Homepage, select Manage -&gt; Data page and then click the UPLOAD DATASET button.</p> </li> <li> <p>Drag and drop <code>sample_bc_credit_data.sav</code> to the upload file selector, or click to browse and select the file. The filename <code>sample_bc_credit_data.sav</code> should appear on the selected file list. Click CONFIRM UPLOAD to upload the file.    </p> </li> <li> <p>Once the file has been uploaded, click the back arrow <code>&lt;-</code> once to return the dataset list page. You should now see the uploaded dataset appear in the list.    </p> </li> </ol>"},{"location":"guided_example/deploy_your_plugin/#generating-the-report","title":"Generating the Report","text":"<ol> <li> <p>It is time to run the plugin. In the homepage, click on \"Create New Project\":    </p> </li> <li> <p>Fill in the project details and click \"Next\" on the top right:    </p> </li> <li> <p>In the Report Template Selection page, Click Create New Report Template to create a report from scratch.    </p> </li> <li> <p>On the Design Report page, drag your widget from the left panel to the canvas:        Since the widget is a dynamic height widget, the widget height will expand dynamically to fill to the bottom of the canvas. Click on the algorihm and input block dependencies icon to view the list of dependencies for this widget. When you're ready, click \"Next\" on the bottom right.</p> </li> <li> <p>On the Select the Mode, Test Results and User Input page, Click the RUN TESTS button besides My Algorithm to run the test for the algorithm.    </p> </li> <li> <p>Select the model and test datasets upload. Then enter the algorithm parameters. Refer to the following table for reference.</p> Data, Model, and Test Arguments Selected Dataset / Model / Test Arguments Model <code>sample_bc_credit_sklearn_linear.LogisticRegression.sav</code> Testing Dataset <code>sample_bc_credit_data.sav</code> Ground Truth Dataset <code>sample_bc_credit_data.sav</code> Ground Truth Column <code>default</code> Feature Name <code>gender</code> <p> Click Run Test button to run the test.</p> </li> <li> <p>When you are ready, click on Run Test button on the bottom right to run the test.</p> </li> <li> <p>You should see the list of tests that are running or have previously been run from the portal. When the algorithm is running, it's status is PENDING. Once the My Algorithm has completed running, it's status will be reflected as SUCCESS or ERROR.</p> <p>Note</p> <p>If the algorithms is unable to run due to error, the status will be set to ERROR and you can view the error log by clicking the View Error button.</p> </li> <li> <p>Click the Back to Project button on the top left to return to the project. Now click the ADD INPUT button to enter the user input for My Input Block. Enter a name for this input and then some values in the First name and Last name fields.</p> <p>Click the Submit button on the bottom right to create a new input.</p> <p></p> </li> <li> <p>Now from the Select the Mode, Test Results and User Input page, select the AI Model and the newly created Test Results and User Inputs.     </p> </li> <li> <p>Click the Next button on the bottom right to view the web report.     </p> </li> </ol> <p>Congratulations! You have generated your first report. </p>"},{"location":"guided_example/introduction_to_plugins/","title":"Introduction to Plugins","text":""},{"location":"guided_example/introduction_to_plugins/#ai-verify-plugins","title":"AI Verify Plugins","text":"<p>AI Verify Plugins are the modular building blocks that power AI Verify. It is extensible and dynamically loaded onto AI Verify. Here are some examples of what you can achieve with plugins.</p> <ul> <li>Add a custom widget to display result graphs on the report</li> <li>Create new testing algorithms to enhance testing capabilities in AI Verify</li> </ul>"},{"location":"guided_example/introduction_to_plugins/#anatomy-of-a-plugin","title":"Anatomy of a Plugin","text":"<p>The diagram shows an example of the plugin structure.</p> <p></p> <p>Each plugin comes packaged in a zip file with the following file structure. It can contain one or more components.</p>"},{"location":"guided_example/introduction_to_plugins/#plugin-components","title":"Plugin Components","text":"<p>A plugin can extend the functionality of AI Verify in four ways:</p> Type of Component Description Algorithm Extend AI Verify with new testing algorithm to run technical test on AI model Widget Extend AI Verify with new visualisation for customised report Input Block Extend AI Verify with new requested parameters from the user Template Extend AI Verify with unique and reusable report templates"},{"location":"guided_example/introduction_to_plugins/#terminology","title":"Terminology","text":"Term Definition plugin AI Verify plugin that can be installed using the AI Verify portal. component Each AI Verify plugin consists of one or more components and can be used to extend the functionality of the system. These are listed in details below. gid Global Identifier. All plugins requires a unique global identifier that is used to identify the plugin. See Widget for more details cid Component ID. Unique ID that identifies the component within the plugin. See Widget for more details"},{"location":"guided_example/introduction_to_plugins/#algorithm","title":"Algorithm","text":"<p>Each algorithm has its own subfolder under the algorithms folder named with the algorithm id. For example, algorithmA should have a sub-folder called \"algorithmA\" under the algorithms folder.</p>"},{"location":"guided_example/introduction_to_plugins/#widget-input-block-and-template","title":"Widget, Input Block and Template","text":"<p>Each instance of the components should be saved under the component folder; and the filenames of the component should correspond to the component cid. For example, widgetA should have the following files under the widgets folder.</p> <ul> <li>widgetA.meta.json</li> <li>widgetA.mdx</li> </ul>"},{"location":"guided_example/your_first_algorithm/","title":"Creating your First Algorithm Component","text":"<p>In this example, you will be building an algorithm component that takes in a feature value from the user and prints out that value in a generated report. </p> <p>There are three objectives in this algorithm component example:</p> <ol> <li>Modify the input schema for the algorithm to receive user input</li> <li>Modify the output schema and and write code to return the expected output</li> <li>Modify the testing codes</li> </ol>"},{"location":"guided_example/your_first_algorithm/#generating-the-algorithm-component-project","title":"Generating the algorithm component project","text":"<p>Algorithms are stored under the my_plugin/algorithms folder. From your terminal, use <code>aiverify-plugin ga</code> to generate an algorithm component template for your new algorithm.</p> <pre><code># Navigate to the plugin project directory\ncd my_plugin\n\n# Generate the algorithm template\naiverify-plugin ga my_algorithm --name \"My Algorithm\" --description \"This algorithm returns the value of the feature name selected by the user.\"\n</code></pre> <p>Yay! You have generated an algorithm component project to create your first algorithm. Verify that the directory <code>algorithms/my_algorithm</code> exists in your current directory.</p> <pre><code>ls algorithms/my_algorithm\n</code></pre> <p>You should see the files generated for the algorithm component under the directory. For more information on the files generated, see Understanding your algorithm project.</p>"},{"location":"guided_example/your_first_algorithm/#check-the-algorithm-meta-data","title":"Check the Algorithm Meta Data","text":"<p>Open the file <code>algo.meta.json</code> under the algorithms/my_algorithm folder and check that the properties are set correctly as shown below:</p> algo.meta.json<pre><code>{\n\"cid\": \"my_algorithm\",\n\"gid\": \"my_plugin\",\n\"name\": \"My Algorithm\",\n\"modelType\": [\n\"classification\"\n],\n\"version\": \"0.1.0\",\n\"author\": \"Example Author\",\n\"description\": \"This algorithm returns the value of the feature name selected by the user.\",\n\"tags\": [\n\"My Algorithm\",\n\"classification\"\n],\n\"requireGroundTruth\": true,\n\"requiredFiles\": [\n\"AUTHORS.rst\",\n\"CHANGELOG.md\",\n\"pyproject.toml\",\n\"LICENSE\",\n\"my_algorithm\",\n\"README.md\",\n\"requirements.txt\",\n\"syntax_checker.py\"\n]\n}\n</code></pre>"},{"location":"guided_example/your_first_algorithm/#modifying-input-schema","title":"Modifying input schema","text":"<p>First, modify <code>input.schema.json</code> to request an input called <code>feature_name</code> from the user when the user uses this algorithm. Notice the highlighted lines that requires a <code>feature_name</code> field, and the properties of the <code>feature_name</code> is also defined.</p> input.schema.json<pre><code>{\n\"title\": \"Algorithm Plugin Input Arguments\",\n\"description\": \"A schema for algorithm plugin input arguments\",\n\"type\": \"object\",\n\"required\": [\n\"feature_name\"\n],\n\"properties\": {\n\"feature_name\": {\n\"title\": \"Feature Name\",\n\"description\": \"Indicate the feature name to be extracted from the data file\",\n\"type\": \"string\"\n}\n}\n}\n</code></pre>"},{"location":"guided_example/your_first_algorithm/#modifying-command-line-arguments","title":"Modifying Command Line Arguments","text":"<p>The file <code>__main__.py</code> serves as the entry point to call the algorithm via comamnd line. The file <code>plugin_init.py</code> contains the logic to parse the command line arguments and pack it into the right input format to be passed to the underlying algorithm.</p> <p>Note</p> <p>The input arguments should be consistent with the arguments specified in <code>input.schema.json</code>.</p> <p>Modify <code>plugin_init.py</code> to add <code>feature_name</code> as input argument to method <code>parse_input_args()</code>.</p> plugin_init.py<pre><code>def parse_input_args():\nglobal parser\nparser.add_argument(\"--data_path\", required=True, help=\"Path to the data file.\")\nparser.add_argument(\"--model_path\", required=True, help=\"Path to the model file.\")\nparser.add_argument(\n\"--ground_truth_path\", required=True, help=\"Path to the ground truth data file.\"\n)\nparser.add_argument(\n\"--ground_truth\",\nrequired=True,\nhelp=\"The ground truth column name in the data.\",\n)\nparser.add_argument(\n\"--run_pipeline\",\naction=argparse.BooleanOptionalAction,\nhelp=\"Whether to run the test as a pipeline (default: False).\",\n)\nparser.add_argument(\n\"--model_type\",\nrequired=True,\nchoices=[\"CLASSIFICATION\", \"REGRESSION\"],\nhelp=\"The type of model (CLASSIFICATION or REGRESSION).\",\n)\nparser.add_argument(\n\"--core_modules_path\",\ndefault=\"\",\nhelp=\"Path to the core modules (default: empty).\",\n)\n# Add additional arguments as needed\nparser.add_argument(\"--feature_name\", default=\"\", help=\"Indicate the feature name to be extracted from the data file.\")\n</code></pre> <p>Then update method <code>invoke_plugin()</code> to add the arguments to be passed to the algorithms as highlighted.</p> plugin_init.py<pre><code>def invoke_plugin():\n# Parse the arguments\nargs = parser.parse_args()\n# Determine the value of run_pipeline\nif args.run_pipeline is None:\nrun_pipeline = False  # Default to False if not provided\nelse:\nrun_pipeline = args.run_pipeline\n# Map string argument to ModelType enum\nmodel_type = ModelType[args.model_type]\n# Add additional arguments to the plugin_argument_values dictionary as needed\nplugin_argument_values = {\n\"feature_name\": args.feature_name,\n}\nprint(\"*\" * 20)\n# Debugging prints\nprint(\nf\"Running with the following arguments:\\n\"\nf\"Data Path: {args.data_path}\\n\"\nf\"Model Path: {args.model_path}\\n\"\nf\"Ground Truth Path: {args.ground_truth_path}\\n\"\nf\"Ground Truth: {args.ground_truth}\\n\"\nf\"Run Pipeline: {run_pipeline}\\n\"\nf\"Model Type: {model_type}\\n\"\nf\"Core Modules Path: {args.core_modules_path}\"\n)\nprint(\"*\" * 20)\ntry:\n# Create an instance of AlgoInit with defined paths and arguments and Run.\nplugin_test = AlgoInit(\nrun_pipeline,\nargs.core_modules_path,\nargs.data_path,\nargs.model_path,\nargs.ground_truth_path,\nargs.ground_truth,\nmodel_type,\nplugin_argument_values, # Uncomment this line if additional arguments are added\n)\nplugin_test.run()\nexcept Exception as exception:\nprint(f\"Exception caught while running the plugin test: {str(exception)}\")\n</code></pre>"},{"location":"guided_example/your_first_algorithm/#modifying-algorithm","title":"Modifying Algorithm","text":"<p>Modify <code>algo.py</code> to receive and return the data of the requested <code>feature_name</code>. </p> <p>Tip</p> <p>All codes generated has been annotated with <code>TODO:</code> for users to quickly navigate to areas that require code modification.</p> <p>Next, update the <code>generate</code> method to retrieve the return the values of the selected <code>feature_name</code> in a given sample data file.</p> my_algorithm.py<pre><code>    def generate(self) -&gt; None:\n\"\"\"\n        A method to generate the algorithm results with the provided data, model, ground truth information.\n        \"\"\"\n# Retrieve data information\nself._data = self._data_instance.get_data()\n# TODO: Insert algorithm logic for this plug-in.\n# Retrieve the input arguments\nmy_user_defined_feature_name = self._input_arguments['feature_name']\n# Get the values of the feature name and convert to a list.\nself._results = {\n\"my_expected_results\": list(self._data[my_user_defined_feature_name].values)\n}\n# Update progress (For 100% completion)\nself._progress_inst.update(1)\n</code></pre> <p>Lastly, update the <code>output.schema.json</code> to return the expected results. This file will be validated against the output to ensure that the results (see line 180 in the previous code snippet) adhere to the output schema.</p> <p>In this algorithm, the expected output will be stored in a list (or array) named <code>my_expected_results</code>.  There must be at least 10 items in the list, and the items must have the type <code>number</code> (as shown in the highlighted lines).</p> output.schema.json<pre><code>{\n\"title\": \"Algorithm Plugin Output Arguments\",\n\"description\": \"A schema for algorithm plugin output arguments\",\n\"type\": \"object\",\n\"required\": [\"my_expected_results\"],\n\"minProperties\": 1,\n\"properties\": {\n\"my_expected_results\": {\n\"description\": \"Algorithm Output\",\n\"type\": \"array\",\n\"minItems\": 10,\n\"items\": {\"type\": \"number\"}\n}\n}\n}\n</code></pre>"},{"location":"guided_example/your_first_algorithm/#run-algorithm","title":"Run Algorithm","text":"<p>For this algorithm, we call the algorithm from the command line using sample data and model files from the <code>aiverify</code> github repository.</p> <p>First install the algorithm.</p> <pre><code>cd my-first-plugin/algorithms/my-algo\npip install -e .\n</code></pre> <p>Now run the algorithm.</p> <pre><code>root_path=\"https://github.com/aiverify-foundation/aiverify/raw/refs/heads/main/stock-plugins/user_defined_files\"\npython -m my_algorithm \\\n--data_path $root_path/data/sample_bc_credit_data.sav \\\n--model_path $root_path/model/sample_bc_credit_sklearn_linear.LogisticRegression.sav \\\n--ground_truth_path $root_path/data/sample_bc_credit_data.sav \\\n--ground_truth default \\\n--model_type CLASSIFICATION \\\n--feature_name gender\n</code></pre> <p>Note</p> <p>Ground truth is optional so if your algorithm does not require ground truth, <code>ground_truth_path</code> and <code>ground_truth</code> can be left as an empty string <code>\"\"</code>.</p> <p>Next, run <code>aiverify-plugin testa</code> to test your algorithm.</p>"},{"location":"guided_example/your_first_algorithm/#test-algorithm","title":"Test Algorithm","text":"<p>Sample unit tests are generated under the <code>tests</code> directory and should be updated for the algorithm.</p>"},{"location":"guided_example/your_first_algorithm/#update-test_e2epy","title":"Update test_e2e.py","text":"<p>Update the test data and model files, as well as the input arguments.</p> test_e2e.py<pre><code>binary_classification_pipeline = {\n\"data_path\": str(\n\"https://github.com/aiverify-foundation/aiverify/raw/refs/heads/main/stock-plugins/user_defined_files/data/sample_bc_credit_data.sav\"\n),\n\"model_path\": str(\"https://github.com/aiverify-foundation/aiverify/raw/refs/heads/main/stock-plugins/user_defined_files/model/sample_bc_credit_sklearn_linear.LogisticRegression.sav\"),\n\"ground_truth_path\": str(\n\"https://github.com/aiverify-foundation/aiverify/raw/refs/heads/main/stock-plugins/user_defined_files/data/sample_bc_credit_data.sav\"\n),\n\"run_pipeline\": False,\n\"model_type\": ModelType.CLASSIFICATION,\n\"ground_truth\": \"default\",\n\"plugin_argument_values\": {\n\"feature_name\": \"gender\",\n}\n}\n</code></pre> <p>Add the input arguments to <code>AlgoInit</code> call. test_e2e.py<pre><code>def test_plugin(data_set):\n# Create an instance of PluginTest with defined paths and arguments and Run.\ncore_modules_path = \"\"\nplugin_test = AlgoInit(\ndata_set[\"run_pipeline\"],\ncore_modules_path,\ndata_set[\"data_path\"],\ndata_set[\"model_path\"],\ndata_set[\"ground_truth_path\"],\ndata_set[\"ground_truth\"],\ndata_set[\"model_type\"],\ndata_set[\"plugin_argument_values\"]\n)\nplugin_test.run()\njson_file_path = Path.cwd() / \"output\" / \"results.json\"\nassert json_file_path.exists()\n</code></pre></p>"},{"location":"guided_example/your_first_algorithm/#update-test_algopy","title":"Update test_algo.py","text":"<p>Make sure that you are using the right data and model files for the tests.</p> test_algo.py<pre><code># Variables for testing\nvalid_data_path = str(\"https://github.com/aiverify-foundation/aiverify/raw/refs/heads/main/stock-plugins/user_defined_files/data/sample_bc_credit_data.sav\")\nvalid_model_path = str(\n\"https://github.com/aiverify-foundation/aiverify/raw/refs/heads/main/stock-plugins/user_defined_files/model/sample_bc_credit_sklearn_linear.LogisticRegression.sav\"\n)\nvalid_ground_truth_path = str(\n\"https://github.com/aiverify-foundation/aiverify/raw/refs/heads/main/stock-plugins/user_defined_files/data/sample_bc_credit_data.sav\"\n)\n</code></pre> <p>Add the input arguments.</p> test_algo.py<pre><code>    def __init__(self):\ntest_discover_plugin()\n(\ndata_instance,\ndata_serializer_instance,\ndata_error_message,\n) = PluginManager.get_instance(PluginType.DATA, **{\"filename\": valid_data_path})\n(\nmodel_instance,\nmodel_serializer_instance,\nmodel_error_message,\n) = PluginManager.get_instance(\nPluginType.MODEL, **{\"filename\": valid_model_path}\n)\n(\nground_truth_instance,\nground_truth_serializer_instance,\ndata_error_message,\n) = PluginManager.get_instance(\nPluginType.DATA, **{\"filename\": valid_ground_truth_path}\n)\nground_truth = \"default\"\nmodel_type = ModelType.CLASSIFICATION\ninput_args = {\n\"feature_name\": \"gender\"\n}\nexpected_exception = RuntimeError\nexpected_exception_msg = \"The algorithm has failed data validation\"\nlogger_instance = logging.getLogger(\"PluginTestLogger\")\nlogger_instance.setLevel(logging.DEBUG)\n</code></pre>"},{"location":"guided_example/your_first_algorithm/#run-algorithm-test","title":"Run Algorithm Test","text":"<p>Under the algorithm directory, run <code>pytest</code> to run the unit tests.</p> <pre><code>pytest .\n</code></pre> <p>If the test passes (no error messages in terminal), you have successfully completed the creation of the algorithm component. At this stage, you can either deploy your algorithm component as a standalone plugin, or continue to work on other components (eg. another algorithm, widget, input block etc) before packaging it as a single plugin.</p> <p>If the test fails, refer to the troubleshooting guide for help.</p>"},{"location":"guided_example/your_first_inputblock/","title":"Creating your First Input Block Component","text":"<p>In this example, you will be building an input block component that prompts the user to enter their first and last name in a web form.</p> <p>There are three learning objectives in this tutorial:</p> <ol> <li>Create a input block component in the plugin project.</li> <li>Modify the input block component to create a web form with inputs for first and last name</li> </ol>"},{"location":"guided_example/your_first_inputblock/#generating-a-input-block-component","title":"Generating a input block component","text":"<p>Widgets are stored in the my_plugin/inputs folder. Use aiverify-plugin gib to generate your widget.</p> <p>Run the following command to generate a new input block.</p> <pre><code>aiverify-plugin gib \"my_inputblock\" --name \"My Input Block\" --description \"My first Input Block\"\n</code></pre> <p>Verify that the directory <code>inputs</code> exists in your current directory with the files for the input block generated inside.</p> <pre><code>ls inputs\n</code></pre> <p>The following files are created:</p> <ul> <li>my_inputblock.mdx</li> <li>my_inputblock.summary.mdx</li> <li>my_inputblock.meta.json</li> </ul>"},{"location":"guided_example/your_first_inputblock/#check-the-input-block-meta-data","title":"Check the Input Block Meta Data","text":"<p>Open the file <code>my_inputblock.meta.json</code> under the inputs folder and check that the properties are set correctly as shown below:</p> my_inputblock.meta.json<pre><code>{\n\"cid\": \"my_inputblock\",\n\"name\": \"My Input Block\",\n\"description\": \"My first Input Block\"\n}\n</code></pre>"},{"location":"guided_example/your_first_inputblock/#editing-mdx","title":"Editing MDX","text":"<p>Open and edit <code>my_inputblock.mdx</code> to implement the MDX content.</p> my_inputblock.mdx<pre><code>&lt;div style={{ display:\"flex\", flexDirection:\"column\" }}&gt;\n&lt;label htmlFor=\"fname\"&gt;First name:&lt;/label&gt;\n&lt;input style={{ color:'black' }} type=\"text\" id=\"fname\" value={props.data[\"fname\"]} onChange={(e)=&gt;props.onChangeData(\"fname\",e.target.value)} /&gt;\n  &lt;label htmlFor=\"lname\"&gt;Last name:&lt;/label&gt;\n&lt;input style={{ color:'black' }} type=\"text\" id=\"lname\" value={props.data[\"lname\"]} onChange={(e)=&gt;props.onChangeData(\"lname\",e.target.value)} /&gt;\n&lt;/div&gt;\n</code></pre>"},{"location":"guided_example/your_first_inputblock/#editing-summary-mdx","title":"Editing Summary MDX","text":"<p>Open and edit <code>my_inputblock.summary.mdx</code> to update the summary MDX content as highlighted.</p> my_inputblock.summary.mdx<pre><code>{/* Return progress in percentage (0-100) */}\nexport const progress = (data) =&gt; {\n// TODO: replace below code with percentage of user completion.\nif (!data)\nreturn 0;\nconst totalKeys = 2;\nconst numKeys = Object.values(data).filter(v =&gt; {\nif (typeof (v) === \"string\" || Array.isArray(v)) {\nreturn v.length &gt; 0;\n} else {\nreturn true;\n}\n}).length;\nreturn Math.round((numKeys / totalKeys) * 100);\n}\n{/* Validate data. */}\nexport const validate = (data) =&gt; {\n// TODO: replace below code with data validation. \nreturn true;\n}\n</code></pre> <p>Once you have build your input block, you can proceed to create a widget.</p>"},{"location":"guided_example/your_first_inputblock/#optional-use-the-playground-to-view-the-input-block","title":"(Optional) Use the Playground to view the Input Block.","text":"<p>Run the following command under the plugin directory to launch the Playground.</p> <pre><code>aiverify-plugin playground\n</code></pre> <p>Navigate to http://localhost:5000/InputBlock/my_inputblock to view the input block you have created.</p> <p></p> <p>Once you make any edit to <code>my_inputblock.mdx</code>, you can click the Refresh button to view your changes. The <code>Input Block Meta</code> tab on the right panel display your Input Block meta information.</p> <p>Type some characters in the First and Last Name fields, then select the <code>Data Output</code> tab on the right panel. You should see the field values captured in the data output.</p> <p>To exit the Playground, type <code>ctrl+c</code> to terminate the application.</p>"},{"location":"guided_example/your_first_plugin/","title":"Creating your First Plugin","text":"<p>In this guided example, you will be building a plugin and two type of components: algorithm and widget. See this page for more details on Plugins.</p> <p>First, we will have to create a plugin project. If you haven't setup your environment, follow the instructions on this page before continuing. </p> <p>Info</p> <p>For this guided example, we will be using the my_plugin project folder to store the algorithm and widget components, before using <code>aiverify-plugin zip</code> command to package and deploy the final plugin zip.</p>"},{"location":"guided_example/your_first_plugin/#generating-the-plugin-project","title":"Generating the plugin project","text":"<p>Use <code>aiverify-plugin gp</code> command to generate your plugin project.</p> <pre><code>aiverify-plugin gp my_plugin --name \"My Plugin\" --description \"My First Plugin\" </code></pre> <p>The project folder <code>my_plugin</code> should be generated under the plugin directory. Under the project folder, the following files are generated.</p> <ul> <li>LICENSE</li> <li>README.md</li> <li>plugin.meta.json</li> <li>.gitignore</li> </ul>"},{"location":"guided_example/your_first_plugin/#check-the-plugin-meta-data","title":"Check the Plugin Meta Data","text":"<p>Open the plugin meta file <code>plugin.meta.json</code> and make sure that the meta properties are set correctly as follows:</p> plugin.meta.json<pre><code>{\n\"gid\": \"my_plugin\",\n\"name\": \"My Plugin\",\n\"version\": \"1.0.0\",\n\"description\": \"My First Plugin\",\n\"author\": \"AI Verify\"\n}\n</code></pre> <p>Once you have create the plugin project, you can proceed to add a new algorithm component.</p>"},{"location":"guided_example/your_first_widget/","title":"Creating your First Widget Component","text":"<p>There are three learning objectives in this tutorial:</p> <ol> <li>Create a widget component in the existing plugin project.</li> <li>Modify the widget component to display the results from the completed algorithm component</li> <li>Deploy the widget component</li> </ol>"},{"location":"guided_example/your_first_widget/#generating-a-widget-component","title":"Generating a widget component","text":"<p>Widgets are stored in the my_plugin/widgets folder. Use aiverify-plugin gw to generate your widget.</p> <p>Run the following command to generate a new widget and create a dependency to the algorithm and input block components created earlier.</p> <pre><code>aiverify-plugin gw \"my_widget\" --name \"My Widget\" --description \"My first widget\" --dep \"Algorithm,my_algorithm\" --dep \"InputBlock,my_inputblock\" --minW 12 --dynamicHeight\n</code></pre> <p>Verify that the directory <code>widgets</code> exists in your current directory with the files for the widgets generated inside.</p> <pre><code>ls widgets\n</code></pre> <p>The following files are created:</p> <ul> <li>my_widget.mdx</li> <li>my_widget.meta.json</li> <li>my_algorithm.sample.json</li> <li>my_inputblock.sample.json</li> </ul>"},{"location":"guided_example/your_first_widget/#edit-the-widget-meta-data","title":"Edit the Widget Meta Data","text":"<p>Open the file <code>my_widget.meta.json</code> under the widgets folder and add the widget properties are as shown in highlight below below:</p> my_widget.meta.json<pre><code>{\n\"cid\": \"my_widget\",\n\"widgetSize\": {\n\"minW\": 12,\n\"minH\": 1,\n\"maxW\": 12,\n\"maxH\": 36\n},\n\"name\": \"My Widget\",\n\"description\": \"My first widget\",\n\"dynamicHeight\": true,\n\"dependencies\": [\n{\n\"cid\": \"my_algorithm\"\n},\n{\n\"cid\": \"my_inputblock\"\n}\n],\n\"mockdata\": [\n{\n\"type\": \"Algorithm\",\n\"cid\": \"my_algorithm\",\n\"datapath\": \"my_algorithm.sample.json\"\n},\n{\n\"type\": \"InputBlock\",\n\"cid\": \"my_inputblock\",\n\"datapath\": \"my_inputblock.sample.json\"\n}\n],\n\"properties\": [\n{\n\"key\": \"title\",\n\"helper\": \"Set the widget title (default \\\"Hello World\\\")\",\n\"default\": \"Hello World\"\n}\n]\n}\n</code></pre>"},{"location":"guided_example/your_first_widget/#editing-sample-algorithm-file","title":"Editing sample algorithm file","text":"<p>Open and edit <code>my_algorithm.sample.json</code> with a valid sample output from the algorithm or input block. This sample data will be passed to the MDX component props in the project canvas, and allows the MDX to display data based on sample input.</p> my_algorithm.sample.json<pre><code>{\"my_expected_results\": [\n33280.0,\n40000.0,\n70000.0,\n50000.0,\n50000.0,\n40000.0,\n50000.0,\n0.0,\n90000.0,\n35000.0,\n80000.0,\n50000.0\n]    }\n</code></pre>"},{"location":"guided_example/your_first_widget/#editing-sample-input-block-file","title":"Editing sample input block file","text":"<p>Open and edit <code>my_inputblock.sample.json</code> with a valid sample output from the algorithm or input block. This sample data will be passed to the MDX component props in the project canvas, and allows the MDX to display data based on sample input.</p> my_inputblock.sample.json<pre><code>{\n\"fname\": \"John\",\n\"lname\": \"Doe\"\n}\n</code></pre>"},{"location":"guided_example/your_first_widget/#editing-mdx","title":"Editing MDX","text":"<p>Open and edit <code>my_widget.mdx</code> to implement the MDX content.</p> my_widget.mdx<pre><code>export const algo_cid = \"my_algorithm\"\nexport const ib_cid = \"my_inputblock\"\n# {props.properties.title}\n{props.getIBData(ib_cid)?(\n&lt;&gt;\n&lt;b&gt;Input Block Data:&lt;/b&gt;\n&lt;p&gt;\n&lt;b&gt;First Name:&lt;/b&gt; {props.getIBData(ib_cid)[\"fname\"]}&lt;br/&gt;\n&lt;b&gt;Last Name:&lt;/b&gt; {props.getIBData(ib_cid)[\"lname\"]}\n&lt;/p&gt;\n&lt;/&gt;\n):(\n&lt;div&gt;No widget data&lt;/div&gt;\n)}\n{props.getResults(algo_cid)?(\n&lt;&gt;\n&lt;b&gt;JSON output of algorithm&lt;/b&gt;\n&lt;pre&gt;{JSON.stringify(props.getResults(algo_cid),null,2)}&lt;/pre&gt;\n&lt;/&gt;\n):(\n&lt;div&gt;No algorithm data&lt;/div&gt;\n)}\n</code></pre> <p>Once you are done with the widget creation, you can proceed to deploy your plugin.</p>"},{"location":"guided_example/your_first_widget/#optional-use-the-playground-to-view-the-widget","title":"(Optional) Use the Playground to view the Widget.","text":"<p>Run the following command under the plugin directory to launch the Playground.</p> <pre><code>aiverify-plugin playground\n</code></pre> <p>Navigate to http://localhost:5000/ReportWidget/my_widget to view the widget you have created.</p> <p></p> <p>Once you make any edit to <code>my_widget.mdx</code>, you can click the Refresh button to view your changes. The <code>Widget Meta</code> tab on the right panel display your Widget meta information.</p> <p>Select the <code>Properties</code> tab to see the widget properties defined. Then change the <code>title</code> property to other values. Click Refresh button to see the widget title updated to the new value you enter.</p> <p></p> <p>To exit the Playground, type <code>ctrl+c</code> to terminate the application.</p>"},{"location":"plugins/","title":"Plugin System","text":""},{"location":"plugins/#description","title":"Description","text":"<p>This section documents the plugin system of AI Verify.</p>"},{"location":"plugins/#list-of-documentation-for-the-plugin-system-of-ai-verify","title":"List of Documentation for the Plugin System of AI Verify","text":"<ol> <li>Algorithm</li> <li>Widget &amp; Input Block</li> <li>Report Template</li> <li>Plugin</li> </ol>"},{"location":"plugins/Plugin_Tool/","title":"AI Verify Plugin Tool","text":"<p>The aiverify-plugin tool is a command-line tool that help widget and input block developers to develop and scaffold AI Verify plugin projects directly from command line. </p>"},{"location":"plugins/Plugin_Tool/#basic-use","title":"Basic Use","text":"<p>Once the tool is installed, it can be invoked with <code>aiverify-plugin</code>. The command line syntax is as follows:</p> <pre><code>aiverify-plugin &lt;cmd&gt; [args]\n</code></pre> <p>The second argument  is the command to run. The <code>--help</code> argument will output the help menu for the tool or the command. For example, <pre><code>aiverify-plugin --help\naiverify-plugin generate-plugin --help\n</code></pre>"},{"location":"plugins/Plugin_Tool/#commands","title":"Commands","text":"<p>You can view the list of commands with <code>aiverify-plugin --help</code>.</p> <pre><code>aiverify-plugin &lt;cmd&gt; [args]\n\nCommands:\n  aiverify-plugin generate-plugin [gid]      Generate skeleton AI Verify plugin project                  [aliases: gp]\n  aiverify-plugin generate-widget &lt;cid&gt;      Generate skeleton AI Verify widget                          [aliases: gw]\n  aiverify-plugin generate-inputblock &lt;cid&gt;  Generate skeleton AI Verify input block                    [aliases: gib]\n  aiverify-plugin generate-algorithm &lt;cid&gt;   Generate skeleton AI Verify algorithm                       [aliases: ga]\n  aiverify-plugin zip [pluginDir]            Create the plugin zip file\n  aiverify-plugin validate                   Validate AI Verify plugin\n  aiverify-plugin test-widget                Run the plugin tests for widgets and input blocks        [aliases: testw]\n  aiverify-plugin test-algorithm             Run the plugin tests for algorithms                      [aliases: testa]\n  aiverify-plugin test-all                   Run all the tests for widgets, input blocks and algorithms with default\n                                              options\n  aiverify-plugin playground                 Launch the plugin playround\n\nOptions:\n  --help  Show help                                                                                           [boolean]\n</code></pre> <p>Tip: Using the gp, gw and gib commands on existing plugin or component will update the component meta data with any new arguments specified. To overwrite existing meta properties, use the --force argument.</p>"},{"location":"plugins/Plugin_Tool/#generate-plugin-alias-gp","title":"generate-plugin [alias: gp]","text":"<p>This command generates a skeleton plugin project.</p> <pre><code>aiverify-plugin generate-plugin [gid]\n\nGenerate skeleton AI Verify plugin project\n\nPositionals:\n  gid  Plugin Global ID                           [string] [default: If not specified, a random UUID will be generated.]\n\nOptions:\n  --help         Show help                                                                                     [boolean]\n  --name         Plugin name. If not provided will be set to same as gid.                                       [string]\n  --version      Plugin version. Version should be a valid semantic version.                 [string] [default: \"1.0.0\"]\n  --author       Plugin author                                                           [string] [default: \"AI Verify\"]\n  --description  Plugin description                                                                             [string]\n  --license      Plugin opensource license\n         [string] [choices: \"Apache Software License 2.0\", \"MIT\", \"BSD-3\", \"GNU GPL v3.0\", \"Mozilla Public License 2.0\"]\n                                                                                [default: \"Apache Software License 2.0\"]\n  --url          Plugin URL                                                                                     [string]\n  --force        Overwrite existing settings. By default existing settings will not be overwritten.            [boolean]\n</code></pre> <p>If the command run is successful, the tool will generate a folder with the same name as the plugin gid and the following files:</p> File Description plugin.meta.json Contains the plugin meta information README.md Contains generic README for the plugin LICENSE Contains the selected license file for the plugin project .gitignore List of untracked files for git to ignore"},{"location":"plugins/Plugin_Tool/#examples","title":"Examples","text":"<p>To generate plugin with random gid. <pre><code>aiverify-plugin gp --name \"My Plugin\" --description \"Just a test plugin\"\n</code></pre></p> <p>To generate plugin with specific gid. <pre><code>aiverify-plugin gp \"myplugin\" --name \"My Plugin\" --description \"Just a test plugin\"\n</code></pre></p>"},{"location":"plugins/Plugin_Tool/#generate-widget-alias-gw","title":"generate-widget [alias: gw]","text":"<p>To generate a widget, cd to a plugin project folder and run the following command.</p> <pre><code>aiverify-plugin generate-widget &lt;cid&gt;\n\nGenerate skeleton AI Verify widget\n\nPositionals:\n  cid  Widget Component ID                                                                           [string] [required]\n\nWidget Sizes\n  --minW  Specify the minimum widget width (1-12)                                                  [number] [default: 1]\n  --minH  Specify the minimum widget height (1-36)                                                 [number] [default: 1]\n  --maxW  Specify the maximum widget width (1-12)                                                 [number] [default: 12]\n  --maxH  Specify the maximum widget height (1-36)                                                [number] [default: 36]\n\nOptions:\n  --help               Show help                                                                               [boolean]\n  --name               Widget name. If not provided will be set to same as cid.                                 [string]\n  --description        Widget description                                                                       [string]\n  --tag                Allow users to search and filter by tags                                                  [array]\n  --dep, --dependency  Option format: \"&lt;Algorithm|InputBlock&gt;,cid[,gid,version]\". Add the option as dependency in the\n                       widget meta config.                                                                       [array]\n  --prop, --property   Option format: \"key[,helper][,default]\". Add the option as property in the widget meta config.\n                                                                                                                 [array]\n  --dynamicHeight      Indicate that this widget has dynamic height.                                           [boolean]\n  --force              Overwrite existing settings. By default existing settings will not be overwritten.      [boolean]\n  --pluginDir          Path to plugin directory                                                  [string] [default: \".\"]\n</code></pre> <p>Notes: * For every dependencies defined, a sample json file \"\\&lt;gid&gt;.sample.json\" will be created.</p> <p>Upon successful command run, the following files are generated under the widgets sub-folder:</p> File Description \\&lt;widget cid&gt;.meta.json Contains the widget meta information \\&lt;widget cid&gt;.mdx MDX script for the widget \\&lt;dep gid&gt;.sample.json JSON file containing sample data for each dependency specified"},{"location":"plugins/Plugin_Tool/#examples_1","title":"Examples","text":"<p>Generate a widget without any dependencies and properties. <pre><code>aiverify-plugin gw \"mywidget\" --name \"My Widget\" --description \"Widget without dependencies and properties\"\n</code></pre></p> <p>Generate a widget with a couple of tags. <pre><code>aiverify-plugin gw \"mywidget\" --name \"My Widget\" --description \"Widget with tags\" --tag mytag1 --tag mytag2\n</code></pre></p> <p>Generate a widget with minimum width set to 12. <pre><code>aiverify-plugin gw \"mywidget\" --name \"My Widget\" --description \"Widget with minW 12\" --minW 12\n</code></pre></p> <p>Generate a widget with properties. <pre><code>aiverify-plugin gw \"mywidget\" --name \"My Widget\" --description \"Widget with properties\" --prop \"title,Title text to display,Hello World\"\n</code></pre></p> <p>Generate a widget with dependencies. <pre><code>aiverify-plugin gw \"mywidget\" --name \"My Widget\" --description \"Widget with dependencies\" --dep \"Algorithm,my-fake-algo-gid,1.1.0\" --dep \"InputBlock,my-input-block\"\n</code></pre></p>"},{"location":"plugins/Plugin_Tool/#generate-inputblock-alias-gib","title":"generate-inputblock [alias: gib]","text":"<p>To generate an input block, cd to a plugin project folder and run the following command.</p> <p><pre><code>aiverify-plugin generate-inputblock &lt;cid&gt;\n\nGenerate skeleton AI Verify input block\n\nPositionals:\n  cid  Input Block Component ID                                                                      [string] [required]\n\nOptions:\n  --help         Show help                                                                                     [boolean]\n  --name         Input Block name. If not provided will be set to same as cid.                                  [string]\n  --description  Input Block description                                                                        [string]\n  --group        Input Block group. Input blocks of the same group name (case-senstive) will be grouped together in the\n                 input block list                                                                               [string]\n  --width        Width of input block dialog box                        [string] [choices: \"xs\", \"sm\", \"md\", \"lg\", \"xl\"]\n  --fullScreen   Whether the input block dialog should be full screen                                          [boolean]\n  --force        Overwrite existing files or settings. By default existing files and settings will not be overwritten.\n                                                                                                               [boolean]\n  --pluginDir    Path to plugin directory                                                        [string] [default: \".\"]\n</code></pre> Upon successful command run, the following files are generated under the inputs sub-folder:</p> File Description \\&lt;input block cid&gt;.meta.json Contains the input block meta information \\&lt;input block cid&gt;.mdx MDX script for the input block \\&lt;input block cid&gt;.ts Typescript containing the input block summary methods"},{"location":"plugins/Plugin_Tool/#examples_2","title":"Examples","text":"<p>Generate with input block. <pre><code>aiverify-plugin gib \"myinputblock\" --name \"My Input Block\" --description \"An input block\"\n</code></pre></p> <p>Generate with input block with dialog width \"lg\" <pre><code>aiverify-plugin gib \"myinputblock\" --name \"My Input Block\" --description \"An input block with dialog width lg\" --width lg\n</code></pre></p>"},{"location":"plugins/Plugin_Tool/#generate-algorithm-alias-ga","title":"generate-algorithm [alias: ga]","text":"<p>To generate an Algorithm, cd to a plugin project folder and run the following command.</p> <p><pre><code>aiverify-plugin generate-algorithm &lt;cid&gt;\n\nGenerate skeleton AI Verify algorithm\n\nPositionals:\n  cid  Algorithm Component ID                                                                        [string] [required]\n\nOptions:\n  --help                Show help                                                                              [boolean]\n  --interactive         Prompt for arguments (will ignore rest of command line options)                        [boolean]\n  --author              Author name                                                 [string] [default: \"Example Author\"]\n  --pluginVersion       Plugin version                                                       [string] [default: \"0.1.0\"]\n  --description         Algorithm description                                                                   [string]\n  --tag                 Allow users to search and filter by tags                                                 [array]\n  --modelSupport        Algoritm model support\n                                  [string] [choices: \"Classification\", \"Regression\", \"Both\"] [default: \"Classification\"]\n  --requireGroundTruth  Whether this algorithm require ground truth (--no-requireGroundTruth to indicate not required)\n                                                                                               [boolean] [default: true]\n  --pluginDir           Path to plugin directory                                                 [string] [default: \".\"]\n</code></pre> Upon successful command run, the algorithm boilerplate files are generated under the algorithms/{algorithm cid} sub-folder:</p>"},{"location":"plugins/Plugin_Tool/#zip","title":"zip","text":"<p>This commands create a plugin zip file that can be uploaded to the AI Verify portal using the Plugin Manager.</p> <pre><code>aiverify-plugin zip [pluginDir]\n\nCreate the plugin zip file\n\nPositionals:\n  pluginDir  Path to plugin directory                                                            [string] [default: \".\"]\n\nOptions:\n  --help             Show help                                                                                 [boolean]\n  --skip-validation  Skip validation                                                                           [boolean]\n</code></pre> <p>Notes * By default, the zip command will run validation tests first before creating the plugin zip. The \"--skip-validation\" option allows user to skip the validation step.</p>"},{"location":"plugins/Plugin_Tool/#validate","title":"validate","text":"<p>This command run validate checks on the meta files and MDX scripts under the plugin folder.</p> <pre><code>aiverify-plugin validate\n\nValidate AI Verify plugin\n\nOptions:\n  --help       Show help                                                                                       [boolean]\n  --pluginDir  Path to plugin directory                                                          [string] [default: \".\"]\n</code></pre>"},{"location":"plugins/Plugin_Tool/#test-widget-alias-testw","title":"test-widget [alias: testw]","text":"<p>This command uses Jest to run tests on the input blocks and widgets.</p> <pre><code>aiverify-plugin test-widget\n\nRun the plugin tests for widgets and input blocks\n\nOptions:\n      --help                         Show help                                                                 [boolean]\n      --pluginDir                    Path to plugin directory                                    [string] [default: \".\"]\n      --coverage, --collectCoverage  Indicates that test coverage information should be collected and reported in the\n                                     output.                                                  [boolean] [default: false]\n      --listTests                    Lists all test files that Jest will run given the arguments, and exits.\n                                                                                              [boolean] [default: false]\n      --showConfig                   Print your Jest config and then exits.                   [boolean] [default: false]\n      --watch                        Watch files for changes and rerun tests related to changed files.\n                                                                                              [boolean] [default: false]\n      --watchAll                     Watch files for changes and rerun all tests when something changes.\n                                                                                              [boolean] [default: false]\n      --ci                           When this option is provided, Jest will assume it is running in a CI environment.\n                                                                                              [boolean] [default: false]\n  -u, --updateSnapshot               Use this flag to re-record every snapshot that fails during this test run.\n                                                                                              [boolean] [default: false]\n      --json                         Prints the test results in JSON. This mode will send all other test output and user\n                                     messages to stderr.                                      [boolean] [default: false]\n      --outputFile                   Write test results to a file when the --json option is also specified.     [string]\n</code></pre> <p>By default, the command will run validation and snapshot tests on the input blocks and widgets found under the plugin directory. The snapshots will be saved to <code>__snapshots__</code> folder under the plugin directory. It is recommended that developers add the <code>__snapshots__</code> folder to their project repository. </p> <p>To add additional Jest tests, developers can write their own tests and place them under <code>__tests__</code> folder under the plugin directory.</p>"},{"location":"plugins/Plugin_Tool/#test-algorithm-alias-testa","title":"test-algorithm [alias: testa]","text":"<p>This command run the algorithm test script for each algorithm found under the plugin directory.</p> <pre><code>aiverify-plugin test-algorithm\n\nRun the plugin tests for algorithms\n\nOptions:\n  --help       Show help                                                                                       [boolean]\n  --pluginDir  Path to plugin directory                                                          [string] [default: \".\"]\n  --silent     Do not display the stdout from the algorithm tests on the console.             [boolean] [default: false]\n</code></pre>"},{"location":"plugins/Plugin_Tool/#test-all","title":"test-all","text":"<p>This command runs the tests for all algorithms, input blocks and widgets found under the plugin directory.</p> <pre><code>aiverify-plugin test-all\n\nRun all the tests for widgets, input blocks and algorithms with default options\n\nOptions:\n  --help       Show help                                                                                       [boolean]\n  --pluginDir  Path to plugin directory                                                          [string] [default: \".\"]\n</code></pre>"},{"location":"plugins/Plugin_Tool/#playground","title":"playground","text":"<p>This command launches a web playground app to allow developers to view widgets and input blocks during development.</p> <pre><code>aiverify-plugin playground\n\nLaunch the plugin playround\n\nOptions:\n  --help       Show help                                                                                       [boolean]\n  --pluginDir  Path to plugin directory                                                          [string] [default: \".\"]\n  --port       Playground port to listen on                                                     [number] [default: 5000]\n  --hostname   Playground hostname to listen on                                          [string] [default: \"localhost\"]\n</code></pre> <p>To start the playground, runs the playground command under a plugin directory. The command will scan for the algorithms, widgets and input blocks found under the plugin and launches the playground app listening on http://localhost:5000/ by default. To change the port and hostname, use the options to configure.</p>"},{"location":"plugins/algorithm/aiverify_test_engine/","title":"Understanding the AI Verify Test Engine","text":"<p>The AI Verify Test Engine is a python module under AI Verify Github repository and provides core interfaces, converters, data, model and plugin managers to facilitate the development of tests for AI systems. </p> <p>AI Verify Test Engine is published to PyPI and can be installed using <code>pip</code>.</p> Installation Command Description <code>pip install aiverify-test-engine</code> Installs only the core functionalites. Supports tabular data formats like CSV, as well as Pandas pickle and Joblib files, and Scikit-learn models. <code>pip install aiverify-test-engine[dev]</code> Includes additional dependencies for development. Intended for developers who want to contribute to the project. <code>pip install aiverify-test-engine[tensorflow]</code> Installs optional Tensorflow and Keras dependencies. <code>pip install aiverify-test-engine[pytorch]</code> Installs optional PyTorch dependencies. <code>pip install aiverify-test-engine[gbm]</code> Installs XGBoost and LightGBM packages. Supports serializing models in these formats. <code>pip install aiverify-test-engine[all]</code> Installs the core package along with all additional non development dependencies."},{"location":"plugins/algorithm/aiverify_test_engine/#categories-of-support","title":"Categories of Support","text":"<p>There are four categories of support for algorithms: </p>"},{"location":"plugins/algorithm/aiverify_test_engine/#model","title":"Model","text":"<p>Models are frameworks that are run by algorithms. </p> <p>Models currently supported:</p> <ul> <li>LightGBM</li> <li>Scikit-learn</li> <li>XGBoost</li> <li>PyTorch</li> </ul>"},{"location":"plugins/algorithm/aiverify_test_engine/#model-pipeline","title":"Model Pipeline","text":"<p>Model pipelines are models which apply a list of transforms and final estimator to the data.</p> <p>Model pipelines currently supported:</p> <ul> <li>Scikit-learn</li> <li>PyTorch</li> </ul>"},{"location":"plugins/algorithm/aiverify_test_engine/#deserializer","title":"Deserializer","text":"<p>Deserializers process serialized data and make them into readable objects. Model and data files can sometimes be passed in as a serialized file type (e.g. Joblib). A serialized file is not easily readable and modifiable by humans. If we have the right deserializer for the serialized file, it wil deserialize the file into an object like Pandas dataframe, which users are able to modify. </p> <p>Deserializers currently supported:</p> <ul> <li>Delimiter</li> <li>Joblib</li> <li>Pickle</li> <li>TensorFlow</li> <li>Image</li> </ul>"},{"location":"plugins/algorithm/aiverify_test_engine/#data-type","title":"Data Type","text":"<p>Data type refers to the type of data after it has been deserialized. If the data passed in does not require deserializing (e.g. the data file is <code>csv</code> file), the data type will be whatever is in the data file.</p> <p>Data types currently supported:</p> <ul> <li>Delimiter (colon, comma, pipe, semicolon, space, tab separated values)</li> <li>Pandas</li> <li>Image (JPG, JPEG, PNG)</li> </ul>"},{"location":"plugins/algorithm/algorithm-plugin-in-depth-reference/","title":"In-Depth Reference","text":""},{"location":"plugins/algorithm/algorithm-plugin-in-depth-reference/#understanding-your-installed-packages","title":"Understanding Your Installed Packages","text":""},{"location":"plugins/algorithm/algorithm-plugin-in-depth-reference/#zip","title":"zip","text":"<p><code>zip</code> is a package which compresses and packages a directory into a <code>.zip</code> file. We will be using <code>zip</code> to package the algorithm plugin into a distributable package. To install the package: <pre><code>sudo apt install -y zip\n</code></pre></p>"},{"location":"plugins/algorithm/algorithm-plugin-in-depth-reference/#jq","title":"jq","text":"<p><code>jq</code> is a package which does JSON processing. We will be using <code>jq</code> to extract fields from a JSON configuration file.  To install the package: <pre><code>sudo apt install -y jq\n</code></pre></p>"},{"location":"plugins/algorithm/algorithm-plugin-in-depth-reference/#cookiecutter","title":"Cookiecutter","text":"<p><code>Cookiecutter</code> is a command-line utility Python package that helps with creating projects from project templates. We will be using <code>Cookiecutter</code> to create the algorithm project from our predefined template.  To install Cookiecutter using pip or pip3: <pre><code>pip install cookiecutter\n</code></pre> You can try creating your own Cookiecutter template. Refer to tutorial for more information.</p>"},{"location":"plugins/algorithm/deploying_algorithm/","title":"Deploying","text":""},{"location":"plugins/algorithm/deploying_algorithm/#deploying-and-packaging-your-algorithm-plugin","title":"Deploying and Packaging Your Algorithm Plugin","text":"<p>When you are creating your distribution package with <code>aiverify-plugin zip</code> command, these are the things that will happen for each algorithms to be packed: </p>"},{"location":"plugins/algorithm/deploying_algorithm/#syntax-checking","title":"Syntax checking","text":"<p>There will be a syntax check run on the main Python file (in this case it will be <code>algo.py</code>). This is to ensure that the algorithm can run smoothly before packaging. If the check fails, it means that there are syntax error(s) and you will have to fix the error(s) before continuing. </p>"},{"location":"plugins/algorithm/deploying_algorithm/#test-running-the-algorithm","title":"Test Running the Algorithm","text":"<p>This is the same as testing your algorithm in the previous section. The algorithm's input argument(s) and generated results will be validated against the schema you have defined in <code>input.schema.json</code> and <code>output.schema.json</code> respectively. This is to ensure that the input argument(s) and generated results have the right format and data type. </p>"},{"location":"plugins/algorithm/deploying_algorithm/#adding-in-the-required-files","title":"Adding in the Required Files","text":"<p>There is a predefined list of files that are required (as mentioned in requiredFiles) to be packaged with the algorithm plugin for the algorithm to run. The Python file(s)/directory(s) you have added into <code>requiredFiles</code> will be added into the package as well. </p>"},{"location":"plugins/algorithm/deploying_algorithm/#packaging-the-algorithm-plugin","title":"Packaging the Algorithm Plugin","text":"<p>When all the checks have passed and all the required files have been added, the algorithm component, together with the required files, will be added to the plugin <code>.zip</code> file. The <code>.zip</code> package will be used for distribution. </p>"},{"location":"plugins/algorithm/file_structure/","title":"Understanding Your Algorithm Project","text":""},{"location":"plugins/algorithm/file_structure/#project-directory","title":"Project Directory","text":"<p>After creating the project from Cookiecutter (with <code>your_first_algorithm_plugin</code> as an example), the project directory will look something like this: <pre><code>\u251c\u2500\u2500 AUTHORS.rst\n\u251c\u2500\u2500 CHANGELOG.md\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 run_tests.sh\n\u251c\u2500\u2500 syntax_checker.py\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 my_algorithm\n|   \u251c\u2500\u2500 __main__.py\n|   \u251c\u2500\u2500 __init__.py\n|   \u251c\u2500\u2500 algo.meta.json\n|   \u251c\u2500\u2500 algo.py\n|   \u251c\u2500\u2500 algo_init.py\n|   \u251c\u2500\u2500 plugin_init.py\n|   \u251c\u2500\u2500 input.schema.json\n|   \u251c\u2500\u2500 output.schema.json\n\u251c\u2500\u2500 tests\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 e2e\n|   |   \u251c\u2500\u2500 test_e2e.py\n\u2502   \u251c\u2500\u2500 unit_tests\n|   |   \u251c\u2500\u2500 test_algo.py\n</code></pre></p>"},{"location":"plugins/algorithm/file_structure/#the-key-files-in-the-project","title":"The Key Files in the Project","text":"<ul> <li><code>AUTHORS.rst</code> The name or organisation name of the algorithm developer.</li> <li><code>CHANGELOG.md</code> A log of all notable changes made to this project.</li> <li><code>README.md</code> A default page which is shown on the code repository. It contains the description, license, plugin URL and developers.</li> <li><code>__main__.py</code> Entry point to call the algorithm to be called from command line. </li> <li><code>algo.meta.json</code> The metadata of the type of algorithm, which also serves as a configuration file to manage the files to include for deployment. It contains the cid, name, model type, version, description, tags, whether or not it requires ground truth and the required files for deployment. </li> <li><code>algo.py</code> The file with all the logic of the algorithm. Most, if not all the codes should reside in this file.</li> <li><code>input.schema.json</code> The input schema of the algorithm. It is used to validate against the user's input when running the algorithm.</li> <li><code>output.schema.json</code> The output schema of the algorithm. It is used to validate against the algorithm's generated result.</li> <li><code>pyproject.toml</code> Configuration file used by packaging tool.</li> <li><code>syntax_checker.py</code> A Python script which checks for syntax errors in the main file <code>algo.py</code>.</li> <li><code>tests/</code> The test folder containing the e2e and unit tests. It should be run using <code>pytest .</code></li> </ul>"},{"location":"plugins/algorithm/file_structure/#understanding-the-files-you-need-to-modify","title":"Understanding the Files You Need To Modify","text":"<p>While there are many files included in this project, you will only need to focus on modifying a few files. There are <code>TODO</code> comments in each of these files to guide you on the things you have to modify (please remove the <code>TODO</code> comments when you have modified the required parts). Here are the files:</p>"},{"location":"plugins/algorithm/file_structure/#algopy","title":"<code>algo.py</code>","text":"<p>This file is the heart of the algorithm plugin where the magic happens. Most, if not all the codes will be in this file.</p>"},{"location":"plugins/algorithm/file_structure/#plugin-description","title":"Plugin Description","text":"<p>The following points should be considered when writing the plugin description:</p> <ol> <li>Document the purpose of this plugin.</li> <li>What does this plugin do in general? </li> <li>Are there any limitations for this plugin?</li> <li>Is there anything else that future developers should note or understand?</li> </ol> <p>Example: <pre><code>class Plugin(IAlgorithm):\n\"\"\"\n    # TODO: Update the plugin description below\n    The Plugin(My Algorithm) class specifies methods in generating results for algorithm\n    \"\"\"\n# Some information on plugin\n_name: str = \"My Algorithm\"\n_description: str = \"This algorithm returns the value of the feature name selected by the user.\"\n_version: str = \"0.1.0\"\n_metadata: PluginMetadata = PluginMetadata(_name, _description, _version)\n_plugin_type: PluginType = PluginType.ALGORITHM\n_requires_ground_truth: bool = True\n_supported_algorithm_model_type: List = [ModelType.CLASSIFICATION]\n</code></pre></p>"},{"location":"plugins/algorithm/file_structure/#main-codes-of-the-algorithm","title":"Main Codes of the Algorithm","text":"<p>The <code>generate()</code> method is where your codes will be inserted. When the main file <code>__main__.py</code> is run, it will create an instance of <code>PluginTest()</code> and call its method <code>run()</code>, which will call this method <code>generate()</code>.</p> <pre><code>    def generate(self) -&gt; None:\n\"\"\"\n        A method to generate the algorithm results with the provided data, model, ground truth information.\n        \"\"\"\n# Retrieve data information\nself._data = self._data_instance.get_data()\n# TODO: Insert algorithm logic for this plug-in.\n# Retrieve the input arguments\nmy_user_defined_feature_name = self._input_arguments['feature_name']\n# Get the values of the feature name and convert to a list.\nself._results = {\n\"my_expected_results\": list(self._data[my_user_defined_feature_name].values)\n}\n# Update progress (For 100% completion)\nself._progress_inst.update(1)\n</code></pre> <p>Note</p> <p>The final output of the algorithm must be assigned to <code>self._results</code>. The output will be used to match against the schema defined in <code>output.schema.json</code>.</p> <p>Note</p> <p>Use <code>self._progress_inst</code> to update the progress of the test if the progress data is available.</p>"},{"location":"plugins/algorithm/file_structure/#inputschemajson","title":"<code>input.schema.json</code>","text":"<p>Specifies the schema for the input. This is used to validate the schema of the user's input. Example:</p> <pre><code>{\n\"title\": \"Algorithm Plugin Input Arguments\",\n\"description\": \"A schema for algorithm plugin input arguments\",\n\"type\": \"object\",\n\"required\": [\n\"feature_name\"\n],\n\"properties\": {\n\"feature_name\": {\n\"title\": \"Feature Name\",\n\"description\": \"Indicate the feature name to be extracted from the data file\",\n\"type\": \"string\"\n}\n}\n}\n</code></pre> <ul> <li><code>title</code>: The title of this input schema file </li> <li><code>description</code>: The description of this input schema file</li> <li><code>type</code>: Input type of argument. It should be <code>object</code> by default</li> <li><code>required</code>:  Field(s) which must be present. Add the name of the required field(s) into the list (i.e. <code>required: [required_feature_one, ... ,required_feature_n]</code>)</li> <li><code>properties</code>: Contains the details of the <code>required</code> field(s). Every <code>required</code> field must be included and contain the following details: <ul> <li><code>title</code>: Name of the required field</li> <li><code>description</code>: A brief description of the field with some sample </li> <li><code>type</code>: The type of the required field. It can be <code>array</code>, <code>string</code>, <code>number</code>, etc</li> <li>If the <code>type</code> is <code>array</code>, it must also contain a nested list named <code>items</code>, which contains the <code>type</code> of the element in the <code>array</code> (refer to <code>percentiles</code> in the example). You can include multiple types in the <code>items</code> list if you allow multiple types for the <code>items</code> (i.e. <code>\"items\": {\"type\": \"number\", \"type\": \"string\"}</code>)</li> </ul> </li> </ul> <p>Note</p> <p>The <code>input.schema.json</code> defines the algorithm specific input arguments. Besides the input arguments, all algorithms require the <code>data_path</code>, <code>model_path</code>, <code>model_type</code> and optionally <code>ground_truth_path</code> and <code>ground_truth</code> to be provided as inputs when executing the algorithm.</p>"},{"location":"plugins/algorithm/file_structure/#outputschemajson","title":"<code>output.schema.json</code>","text":"<p>Specifies the schema for the output. This is used to validate the schema of the algorithm's output.  Example: </p> <pre><code>{\n\"title\": \"Algorithm Plugin Output Arguments\",\n\"description\": \"A schema for algorithm plugin output arguments\",\n\"type\": \"object\",\n\"required\": [\"my_expected_results\"],\n\"minProperties\": 1,\n\"properties\": {\n\"my_expected_results\": {\n\"description\": \"Algorithm Output\",\n\"type\": \"array\",\n\"minItems\": 10,\n\"items\": {\"type\": \"number\"}\n}\n}\n}\n</code></pre> <ul> <li><code>title</code>: The title of this output schema file </li> <li><code>description</code>: The description of this output schema file</li> <li><code>type</code>: Input type of argument. It should be <code>object</code> by default</li> <li><code>required</code>:  Field(s) which must be present. Add the name of the required field(s) into the list (i.e. <code>required: [required_feature_one, ... ,required_feature_n]</code>)</li> <li><code>properties</code>: Contains the details of the <code>required</code> field(s). Every <code>required</code> field must be included and contain the following details: <ul> <li><code>description</code>: A brief description of the field with some sample </li> <li><code>type</code>: The type of the required field. It can be <code>array</code>, <code>string</code>, <code>number</code>, etc </li> <li>If the <code>type</code> is <code>array</code>, it must also contain a nested list named <code>items</code>, which contains the <code>type</code> of the element in the <code>array</code> (refer to <code>output_classes</code> in the example). You can include multiple types in the <code>items</code> list if you allow multiple types for the <code>items</code> (i.e. <code>\"items\": {\"type\": \"number\", \"type\": \"string\"}</code>) </li> </ul> </li> </ul>"},{"location":"plugins/algorithm/file_structure/#algometajson","title":"<code>algo.meta.json</code>","text":"<p>The metadata of the algorithm plugin. This file should be autogenerated by Cookiecutter according to the your input during the creation phase. Example:</p> <pre><code>{\n\"cid\": \"my_algorithm\",\n\"gid\": \"my_plugin\",\n\"name\": \"My Algorithm\",\n\"modelType\": [\n\"classification\"\n],\n\"version\": \"0.1.0\",\n\"author\": \"Example Author\",\n\"description\": \"This algorithm returns the value of the feature name selected by the user.\",\n\"tags\": [\n\"My Algorithm\",\n\"classification\"\n],\n\"requireGroundTruth\": true,\n\"requiredFiles\": [\n\"AUTHORS.rst\",\n\"CHANGELOG.md\",\n\"pyproject.toml\",\n\"LICENSE\",\n\"my_algorithm\",\n\"README.md\",\n\"requirements.txt\",\n\"syntax_checker.py\"\n]\n}\n</code></pre> <ul> <li><code>cid</code>: The component ID of the algorithm</li> <li><code>gid</code>: The plugin GID</li> <li><code>name</code>: The name of this algorithm plugin </li> <li><code>modelType</code>: The type(s) of the algorithm model. It can be either <code>classification</code>, <code>regression</code> or both </li> <li><code>version</code>: The version of this algorithm. It defaults to <code>0.1.0</code>. If this algorithm is an improvement of a previous algorithm, you should increase the version accordingly. Refer to Understanding Versioning for more information </li> <li><code>author</code>: The name of the developer or the developer's organisation </li> <li><code>description</code>: A short description on what the algorithm does </li> <li><code>tags</code>: A list of searchable tag(s) for the algorithm (i.e. you can add <code>classification</code> to this list if the algorithm supports it) </li> <li><code>requiresGroundTruth</code>: A boolean value to determine if this algorithm requires ground truth data </li> <li> <p><code>requiredFiles</code>: A list of required files for the algorithm to run. If you have other required file(s) and directories, add the file name into this list </p> <p>Note</p> <p>Do not remove or edit the required files already in the list </p> </li> </ul>"},{"location":"plugins/algorithm/file_structure/#pyprojecttoml","title":"<code>pyproject.toml</code>","text":"<p><code>pyproject.toml</code> is a configuration file used in Python projects to specify project metadata, dependencies, build system requirements, and other settings in a standardized way. It is part of PEP 518 and is supported by modern Python packaging tools such as pip, setuptools, and Poetry.</p> <p>Note</p> <p>By default, only <code>aiverify-test-engine[all]</code> is listed as dependencies for the algorithm project. You should update this file and add in any additional dependencies you require.</p>"},{"location":"plugins/algorithm/testing_algorithm/","title":"Testing Your Algorithm","text":"<p>If the algorithm template is generated using <code>aiverify-plugin</code>, a default <code>test_e2e.py</code> and <code>test_algo.py</code> are generated to be run with <code>pytest</code>. You should modify the test files and update according to your test requirements.</p> <p>To run the tests, execute the following commands under the algorithm directory.</p> <pre><code>pytest .\n</code></pre>"},{"location":"plugins/algorithm/testing_algorithm/#sample-test-data-model-and-ground-truth-files","title":"Sample Test Data, Model and Ground Truth Files","text":"<p>You can use the sample test data and models files found here. As the algorithm inputs support reading of files from URL, you can pass in the URL of raw data files to be used in your tests.</p>"},{"location":"plugins/algorithm/testing_algorithm/#validating-the-input-arguments","title":"Validating the Input Arguments","text":"<p>The algorithm's input argument(s) will be validated against the schema you have defined in <code>input.schema.json</code>. This is to ensure that the input argument(s) have the right format and data type.</p>"},{"location":"plugins/algorithm/testing_algorithm/#validating-the-generated-output","title":"Validating the Generated Output","text":"<p>After running the algorithm, the generated results will be validated against the schema you have defined in <code>output.schema.json</code>. This is to ensure that the generated results from the algorithm have the right format and data type.</p>"},{"location":"plugins/create-algorithm-plugins/create-algorithm-plugins-intro/","title":"Plugin Development Guide","text":"<p>A plugin, short for \"plug-in\" or \"add-on\", is a piece of software that adds a specific functionality or feature to an existing application or system.  Plugins are typically designed to extend the functionality of an existing program, without requiring the user to modify or recompile the original application code.</p> <p>This plugin development guide aims to help algorithm developers to build their own algorithm(s) plugin that adds a new algorithm or capability to the A.I. Verify.</p> <p>Note</p> <p>Before developing your own plugin, it is best to visit our existing plugins to check if it is already available for use.</p> <p>In this section, we are covering topics to be proficient in developing algorithm plugins:</p> <ul> <li>Create your first algorithm plugin    This subsection will help developers follow through the creation phase and develop their first algorithm plugin    which reads in a string input and returns the input string.  </li> <li>In-depth reference    This subsection will help developers read in more details about the generated    files and knowing how the whole algorithm plugin work.  </li> <li>Advanced Topics    This subsection will discuss on advanced topics that developers might need    while developing your own algorithm plugins.  </li> <li>Samples    This subsection will provide samples for developers to reference.</li> </ul>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/","title":"Create Your First Algorithm Plugin","text":"<p>This guide shows you how to create an algorithm plugin and deploy/package it into a distributable file that can be  shared with other users using the test-engine-algo-plugin-template project.</p> <p>The easiest way to understand what an algorithm plugin can do is to create one and see how it works.</p>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#prerequisites","title":"Prerequisites","text":"<p>Before we can do anything in this example, you must have Ubuntu, Python and some dependency packages installed on your machine.  Look below for the necessary OS and packages:</p> <ul> <li> <p>Ubuntu 22.04.2 LTS (Jammy Jellyfish)  This Linux platform is recommended for our plugin development to ensure the perfect plugin creation experience.</p> </li> <li> <p>Python 3.10  This package is compulsory. Python is a programming language that lets you  work more quickly and integrate your systems more effectively.</p> </li> <li> <p>Cookiecutter  This package is a command-line utility that creates projects from cookiecutters (project templates),  e.g. creating a Python package project from a Python package project template. <code>$ pip install --user cookiecutter</code></p> </li> <li> <p>jq  This package is like <code>sed</code> for JSON data. It is a lightweight and flexible command-line JSON processor. <code>$ sudo apt install -y jq</code></p> </li> <li> <p>zip  This package is a command-line utility that provides packaging and compressing (archive) files. <code>$ sudo apt install -y zip</code></p> </li> </ul>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#see-also","title":"See Also","text":"<ul> <li>Understanding Your Installed Packages</li> </ul>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#your-first-algorithm-plugin","title":"Your First Algorithm Plugin","text":""},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#getting-started","title":"Getting Started","text":"<p>To get started, open a <code>terminal</code> on your computer.</p> <p>Then, we will create a copy of the test-engine-algo-plugin-template project. This project is a Cookiecutter template which generates the base algorithm plugin for modification.  <pre><code>$ cookiecutter https://gitlab.com/imda_dsl/t2po/ai-verify/ai-verify-test-engine/test-engine-algo-plugin-template.git\n</code></pre></p> <p>You will be presented with a couple of questions:</p> <ul> <li>author [example_author]: We will use the default. Press Enter.</li> <li>plugin_name [example plugin]: Our plugin name will be called <code>your-first-algorithm-plugin</code>. Press Enter.</li> <li>Choose from 1 [1]: We will use the default. Press Enter.</li> <li>plugin_version [0.1.0]: We will use the default. Press Enter.</li> <li>plugin_description [My example plugin]: Our plugin description will be called <code>Your first algorithm plugin</code>. Press Enter.</li> <li>Select license [1]: We will use the default. Press Enter.</li> <li>Select algo_model_support [1]: We will use the default. Press Enter.</li> <li>Select require_ground_truth [1]:  Our plugin will not need ground_truth. Select 2. Press Enter. </li> </ul> <p>Note</p> <p>The plugin name <code>your-first-algorithm-plugin</code> will automatically be converted to <code>your_first_algorithm_plugin</code>.  The cookiecutter generator will automatically convert the name to create the project slug. Refer to the guide on Package and Module Names.</p> <p>Verify that the directory <code>your_first_algorithm_plugin</code> exists in your current directory: <pre><code>ls | grep your_first_algorithm_plugin\n</code></pre></p> <p> If you do not see the project name, something in the setup is incomplete. Please re-create the project directory through the steps above again.   Yay! You have instantly generated a algorithm plugin project! </p>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#see-also_1","title":"See Also","text":"<ul> <li>Understanding Your Algorithm Project</li> </ul>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#building-the-algorithm-plugin","title":"Building the Algorithm Plugin","text":"<p>Before we start, we should create a virtual environment (venv) to let the project have its independent set  of Python packages. The virtual environment can be anywhere (remember where you put it as you will need to activate it) <pre><code>python3 -m venv .venv\n</code></pre></p> <p>Now that we have created this virtual environment for the project, cd to the directory with the virtual environment and activate it. <pre><code>source .venv/bin/activate\n</code></pre></p> <p>We can see that the environment is activated with the <code>(.venv)</code>: </p>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#installing-the-core-library","title":"Installing the Core Library","text":"<p>Note</p> <p>Before we install the other libraries, ensure that your virtual environment is activated.</p> <p>There is a custom core library required to build algorithms. </p> <p>To download the library, clone the project from our Gitlab repository: <pre><code>$ git clone https://gitlab.com/imda_dsl/t2po/ai-verify/ai-verify-test-engine/test-engine-core.git --branch dev_main\n</code></pre></p> <p>To install the library, cd to the <code>test-engine-core</code> directory: <pre><code>$ pip install dist/test_engine_core-1.0.0.tar.gz\n</code></pre></p>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#installing-prerequisites-for-additional-developers-support","title":"Installing Prerequisites for Additional Developers Support","text":"<p>We have provided additional developers support for reading data files, model files, and serializers. To access these supported tools, you will need to run the script that installs the package requirements.</p> <p>First, you will need to navigate to the project directory: <pre><code>$ cd your_first_algorithm_plugin/\n</code></pre></p> <p>Next, run the <code>tests/install_core_modules_requirements.sh</code> script to install the packages listed in the <code>core_modules</code> directory: (This may take some time) <pre><code>$ tests/install_core_modules_requirements.sh\n</code></pre></p> <p>An example of the installation script running: </p> <p>Now that the script has installed the packages successfully, you can read in data, model files  and manipulate the information and work on the algorithm.</p>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#see-also_2","title":"See Also","text":"<ul> <li>Understanding the Core Modules </li> <li>Understanding Your Algorithm Project</li> </ul>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#developing-the-algorithm-plugin","title":"Developing the algorithm plugin","text":"<p>First, let us try to understand the algorithm plugin that we are trying to implement. Our generated algorithm plugin will take in a sample data, model, ground truth path and ground truth field by default. We will modify the codes to read in the sample data from the sample data path, and the sample model from the  sample model path.   Then, we will request the user to input a feature name which he/she wants to retrieve the data for output.  Finally, we will return the output, which is the data for the requested feature.</p> <p> Now that we are clear on what we want to achieve for this algorithm plugin, open your favorite IDE or text editor to navigate to the project. There are multiple files and directories in the project, but we will focus on a few that will help us create our first algorithm plugin.</p>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#inputschemajson","title":"input.schema.json","text":"<p>First, we will request for the feature name from the user. In this JSON file, we will request for information for our algorithm to work properly.</p> <p>Let us modify the JSON to read in the <code>feature_name</code>:</p> <p>input.schema.json<pre><code>{\n\"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n\"$id\": \"https://pypi.org/project/example_plugin//input.schema.json\",\n\"title\": \"Algorithm Plugin Input Arguments\",\n\"description\": \"A schema for algorithm plugin input arguments\",\n\"type\": \"object\",\n\"required\": [\n\"feature_name\"\n],\n\"properties\": {\n\"feature_name\": {\n\"title\": \"Feature Name\",\n\"description\": \"Indicate the feature name (e.g. Interest_Rate) to be extracted from data file\",\n\"type\": \"string\"\n}\n}\n}\n</code></pre> Notice the highlighted lines that requires a <code>feature_name</code> field, and the properties of the <code>feature_name</code> is also defined.</p>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#reference","title":"Reference","text":"<ul> <li>Fields for input.schema.json</li> </ul>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#your_first_algorithm_pluginpy","title":"your_first_algorithm_plugin.py","text":"<p>Next, we will write the logic to retrieve the information of the requested feature. The generated codes have <code>TODO:</code> comments for users to quickly navigate to places that require modification.</p> <p>TODO #1: <code># TODO: Update the plugin description below</code> This <code>TODO</code> is a reminder that you may need to update the plugin description. We will leave it for now:</p> <p>your_first_algorithm_plugin.py<pre><code>class Plugin(IAlgorithm):\n\"\"\"\n    # TODO: Update the plugin description below\n    The Plugin(your-first-algorithm-plugin) class specifies methods in generating results for algorithm\n    \"\"\"\n# Some information on plugin\n_name: str = \"your-first-algorithm-plugin\"\n_description: str = \"Your first algorithm plugin\"\n_version: str = \"0.1.0\"\n_metadata: PluginMetadata = PluginMetadata(_name, _description, _version)\n_plugin_type: PluginType = PluginType.ALGORITHM\n_requires_ground_truth: bool = False\n</code></pre> </p> <p>TODO #2: <code># TODO: Update the input json schema in input.schema.json</code> This <code>TODO</code> is a reminder that you need to update the input json schema to get your user input parameters We have updated it in the previous step while requesting for <code>feature_name</code>: your_first_algorithm_plugin.py<pre><code>        # Other variables\nself._data = None\nself._results = {\"results\": [0]}\n# TODO: Update the input json schema in input.schema.json\n# Algorithm input schema defined in input.schema.json\n# By defining the input schema, it allows the front-end to know what algorithm input params is\n# required by this plugin. This allows this algorithm plug-in to receive the arguments values it requires.\nself._input_schema = load_schema_file(\nstr(self._base_path / \"input.schema.json\")\n)\n</code></pre> </p> <p>TODO #3: <code># TODO: Update the output json schema in output.schema.json</code> This <code>TODO</code> is a reminder that you need to update the output json schema validate your output. We will update this later. your_first_algorithm_plugin.py<pre><code>    # TODO: Update the output json schema in output.schema.json\n# Algorithm output schema defined in output.schema.json\n# By defining the output schema, this plug-in validates the result with the output schema.\n# This allows the result to be validated against the schema before passing it to the front-end for display.\nself._output_schema = load_schema_file(\nstr(self._base_path / \"output.schema.json\")\n)\n</code></pre> </p> <p>TODO #4: <code># TODO: Insert algorithm logic for this plug-in.</code> This <code>TODO</code> is a reminder that you need to insert your algorithm logic here. In this <code>TODO</code>, we will read the user defined feature name.  As we have defined earlier on that the input schema indicates that the algorithm requires the 'feature name'.  We can now read the requested input argument.</p> <p>After we can retrieve the user input feature name, we can now use this to read the values under this feature name. After reading the values, we convert it into a list to be returned. The algorithm results have to be stored in the <code>self._results</code> variable for the result to be returned.</p> <p>You might have noticed that the <code>self._results</code> is <code>Dict</code>, and the key is <code>my_expected_results</code>. Later in the output schema json section, it shows why we need to have the key as <code>my_expected_results</code>. </p> <p>Note</p> <p>Code examples does not include error checking functionality.</p> your_first_algorithm_plugin.py<pre><code>    def generate(self) -&gt; None:\n\"\"\"\n        A method to generate the algorithm results with the provided data, model, ground truth information.\n        \"\"\"\n# Retrieve data information\nself._data = self._data_instance.get_data()\n# TODO: Insert algorithm logic for this plug-in.\n# Retrieve the input arguments\nmy_user_defined_feature_name = self._input_arguments['feature_name']\n# Get the values of the feature name and convert to a list.\nself._results = {\n\"my_expected_results\": list(self._data[my_user_defined_feature_name].values)\n}\n# Update progress (For 100% completion)\nself._progress_inst.update(1)\n</code></pre>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#reference_1","title":"Reference","text":"<ul> <li>Modifying your_first_algorithm_plugin.py</li> </ul>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#outputschemajson","title":"output.schema.json","text":"<p>Lastly, we will validate the algorithm's output against the schema defined in this file. This is to ensure that the output has the expected fields and types defined in the schema. </p> <p>Let us modify the JSON to define the schema of the expected output.</p> <p>output.schema.json<pre><code>{\n\"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n\"$id\": \"https://pypi.org/project/example_plugin//output.schema.json\",\n\"title\": \"Algorithm Plugin Output Arguments\",\n\"description\": \"A schema for algorithm plugin output arguments\",\n\"type\": \"object\",\n\"required\": [\"my_expected_results\"],\n\"minProperties\": 1,\n\"properties\": {\n\"my_expected_results\": {\n\"description\": \"Algorithm Output\",\n\"type\": \"array\",\n\"minItems\": 10,\n\"items\": {\"type\": \"number\"}\n}\n}\n}\n</code></pre> The expected output will be stored in a list (or array) named <code>my_expected_results</code>.  There must be at least 10 items in the list, and the items must have the type <code>number</code> (as shown in the highlighted lines).</p>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#reference_2","title":"Reference","text":"<ul> <li>Fields for output.schema.json</li> </ul>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#testing-the-algorithm-plugin","title":"Testing the algorithm plugin","text":"<p>Once you are done with your algorithm, it is time to test it with some data and model. To run the test, you will need to modify the main file to read the data, model and ground truth files required for your algorithm to run.</p> <p>__main__.py<pre><code>from tests.plugin_test import PluginTest\nif __name__ == \"__main__\":\n# TODO: Define data, model, ground_truth file location. Requires absolute path.\n# Example:\n# data_path = \"tests/user_defined_files/my_data_file.sav\"\n# model_path = \"tests/user_defined_files/my_model_file.sav\"\n# ground_truth_path = \"tests/user_defined_files/my_ground_truth_file.sav\"\n# ground_truth = \"Interest_Rate\"\ndata_path = \"tests/user_defined_files/sample_data.sav\"\nmodel_path = \"tests/user_defined_files/sample_model.sav\"\nground_truth_path = \"\"\nground_truth = \"\"\n# TODO: Define the plugin input parameters value referenced from input.schema.json\n# Example:\nplugin_argument_values = {\n\"feature_name\": \"Annual_Income\"\n}\n</code></pre> In the example above, we have updated the <code>data_path</code>, <code>model_path</code>, <code>ground_truth_path</code> and <code>ground_truth</code> to the path of the files. We have also updated the <code>plugin_argument_values</code> with the required argument defined in input.schema.json to ensure that the input validation passes.</p> <p>Note</p> <p>Ground truth is optional so if your algorithm does not require ground truth, <code>ground_truth_path</code> and <code>ground_truth</code> can be left as an empty string <code>\"\"</code>.</p> <p>After you have updated the file paths, change directory to the directory with <code>__main__.py</code> and run the test using python or python3: <pre><code>python .\n</code></pre> If the test passes (no error messages in terminal), you are ready to move to the next step to deploy your algorithm plugin. If the test fails, refer to the troubleshooting guide for help.</p>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#reference_3","title":"Reference","text":"<ul> <li>Variables in main.py</li> </ul>"},{"location":"plugins/create-algorithm-plugins/first-algorithm-plugin/#deploying-the-algorithm-plugin","title":"Deploying the Algorithm Plugin","text":"<p>We have provided a script to help deploy your algorithm plugin by packaging it. To run the script, change directory to the directory with the script <code>deploy_plugin.sh</code> and enter: <pre><code>./deploy_plugin.sh\n</code></pre></p> <p>Note</p> <p>A new folder <code>dist</code> will be created. This folder is where the packaged <code>.zip</code> file will be created and placed.</p> <p>Verify that the zip file <code>your_first_algorithm_plugin-0.1.0.zip</code> exists in your <code>dist</code> directory: <pre><code>ls dist | grep your_first_algorithm_plugin\n</code></pre></p> <p>We can see that the is a generated <code>zip</code> file which can be used to share with other developers who are interested in using your algorithm. </p> <p>Congratulations! You have successfully completed your first algorithm plugin! Now that you have learnt how to create your own algorithm plugin, request for input arguments to your algorithm,  know where to write your algorithm magic and retrieve information from user, output the results based on your schema,  perform testing on your algorithm plugin and deploying it for sharing, you should start building more complex algorithm plugins.</p> <p>You may want to check out the Advanced section of the guide.</p>"},{"location":"plugins/create-algorithm-plugins/samples/accumulated-local-effects/","title":"Algorithm - Accumulated Local Effects","text":""},{"location":"plugins/create-algorithm-plugins/samples/accumulated-local-effects/#description","title":"Description","text":"<ul> <li>Performs ALE Discrete and ALE Continuous computation</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/accumulated-local-effects/#license","title":"License","text":"<ul> <li>Licensed under Apache Software License 2.0</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/accumulated-local-effects/#plugin-url","title":"Plugin URL","text":"<ul> <li>Accumulated Local Effects - Gitlab</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/accumulated-local-effects/#developers","title":"Developers","text":"<ul> <li>IMDA-T2E</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/fairness-metrics-toolbox/","title":"Algorithm - Fairness Metrics Toolbox","text":""},{"location":"plugins/create-algorithm-plugins/samples/fairness-metrics-toolbox/#description","title":"Description","text":"<ul> <li>The Fairness Metrics Toolbox (FMT) contains a list of fairness metrics to measure how resources (e.g. opportunities, food, loan, medical help) are allocated among the demographic groups (e.g. married male, married female) given a set of sensitive feature(s) (e.g. gender, marital status).</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/fairness-metrics-toolbox/#license","title":"License","text":"<ul> <li>Licensed under Apache Software License 2.0</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/fairness-metrics-toolbox/#plugin-url","title":"Plugin URL","text":"<ul> <li>Fairness Metrics Toolbox - Gitlab</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/fairness-metrics-toolbox/#developers","title":"Developers","text":"<ul> <li>IMDA-T2E</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/partial-dependence-plot/","title":"Algorithm - Partial Dependence Plot","text":""},{"location":"plugins/create-algorithm-plugins/samples/partial-dependence-plot/#description","title":"Description","text":"<ul> <li>A Partial Dependence Plot (PDP) explains how each feature and its feature value contribute to the predictions.</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/partial-dependence-plot/#license","title":"License","text":"<ul> <li>Licensed under Apache Software License 2.0</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/partial-dependence-plot/#plugin-url","title":"Plugin URL","text":"<ul> <li>Partial Dependence Plot - Gitlab</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/partial-dependence-plot/#developers","title":"Developers","text":"<ul> <li>IMDA-T2E</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/performance-metrics-toolbox/","title":"Algorithm - Performance Metrics Toolbox","text":""},{"location":"plugins/create-algorithm-plugins/samples/performance-metrics-toolbox/#description","title":"Description","text":"<ul> <li>This plugin generates the performance metrics of the model given the set of test dataset.</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/performance-metrics-toolbox/#license","title":"License","text":"<ul> <li>Licensed under Apache Software License 2.0</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/performance-metrics-toolbox/#plugin-url","title":"Plugin URL","text":"<ul> <li>Performance Metrics Toolbox - Gitlab</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/performance-metrics-toolbox/#developers","title":"Developers","text":"<ul> <li>IMDA-T2E</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/shap-toolbox/","title":"Algorithm - SHAP Toolbox","text":""},{"location":"plugins/create-algorithm-plugins/samples/shap-toolbox/#description","title":"Description","text":"<ul> <li>SHAP (SHapley Additive exPlanations) is a game theoretic approach to explain the output of any machine learning model. It connects optimal credit allocation with local explanations using the classic Shapley values from game theory and their related extensions (see papers for details and citations).</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/shap-toolbox/#license","title":"License","text":"<ul> <li>Licensed under Apache Software License 2.0</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/shap-toolbox/#plugin-url","title":"Plugin URL","text":"<ul> <li>SHAP Toolbox - Gitlab</li> </ul>"},{"location":"plugins/create-algorithm-plugins/samples/shap-toolbox/#developers","title":"Developers","text":"<ul> <li>IMDA-T2E</li> </ul>"},{"location":"plugins/widget/","title":"AI Verify Plugin","text":"<p>This section contains documentations for widget and input block developers as well as the aiverify-plugin tool.</p>"},{"location":"plugins/widget/#documentation-and-references","title":"Documentation and References","text":"<ul> <li>Plugin - Explains what is AI Verify Plugin and it's structure</li> <li>Widget - Describes the schemas and files in a widget.</li> <li>Input Block - Describes the schemas and files in an input block.</li> <li>Template - Describes the schemas and files in a template.</li> <li>Shared Library - Explains use of AI Verify Shared Library.</li> <li>AI Verify Plugin Tool - How to use the AI Verify Plugin tool.</li> </ul>"},{"location":"plugins/widget/#guides","title":"Guides","text":"<ul> <li>MDX Guide - Overview of MDX and some examples.</li> </ul>"},{"location":"plugins/widget/InputBlock/","title":"Input Block","text":"<p>Each input block consists of at least three files located under the inputs folder, which follows the following naming convention:</p> <ul> <li>\\&lt;input block cid&gt;.meta.json</li> <li>\\&lt;input block cid&gt;.mdx</li> <li>\\&lt;input block cid&gt;.summary.mdx</li> </ul> <p>Assuming you have created a input block with cid \"sample-input-block\", then there should be the following files under the inputs folder:</p> <ul> <li>sample-input-block.meta.json</li> <li>sample-input-block.mdx</li> <li>sample-input-block.summary.mdx</li> </ul>"},{"location":"plugins/widget/InputBlock/#input-block-meta-data","title":"Input Block Meta Data","text":"<p>During installation, the Plugin Manager will search for and validate the input block meta data according to the schema ai-verify.inputBlock.schema.json schema definitions.</p> Propreties Type Required Description cid string, must match pattern <code>^[a-zA-Z0-9][a-zA-Z0-9-._]*$</code> Yes Unique identifier for the input block within the plugin. name string Yes Input block name. description string No Input block description. group string No Input blocks that have the same group name will be grouped together in the user input page groupNumber integer No Only applicable if group is defined. The group number defines the order of the input block within the group. width string, enum [\"xs\", \"sm\", \"md\", \"lg\", \"xl\"] No Defines the width of the input block dialog box in the user input page. If not set, the width will default to \"md\" fullScreen boolean No Whether the dialog box in the input block should be in fullscreen mode. If this is set to true, the width property is not used <p>Note: The input block meta data does not contain a gid property as it is automatically inferred and referenced using the format</p> <p>\\&lt;plugin gid&gt;:\\&lt;input block cid&gt;</p>"},{"location":"plugins/widget/InputBlock/#example","title":"Example","text":"<pre><code>{\n  \"cid\": \"sample-input-block\",\n  \"name\": \"Sample Input Block\",\n  \"description\": \"This is a sample input block\",\n  \"group\": \"Sample Group\",\n  \"width\": \"md\",\n  \"fullScreen\": false\n}\n</code></pre>"},{"location":"plugins/widget/InputBlock/#input-block-mdx","title":"Input Block MDX","text":"<p>The input blocks are launched as dialog in the user input page, with the width of the dialog box depending on the width property in the meta data. </p> <p>The MDX are loaded as React components and the component properties are passed and accessed as props global variable. </p>"},{"location":"plugins/widget/InputBlock/#input-block-props","title":"Input Block Props","text":"Propreties Type Description data object Key-Value Object containing the user input data saved onChangeData (key: string, value: any) =&gt; void Function to save user data, e.g. <code>props.onChangeData(\"mykey\",\"Hello World\")</code>"},{"location":"plugins/widget/InputBlock/#input-block-summary","title":"Input Block Summary","text":"<p>For each input block, there should be a summary file \\&lt;input block cid&gt;.summary.mdx that is imported by the AI Verify portal. The script MUST implement and export the following methods. For Example,</p> <pre><code>{/* Return summary of data */}\nexport const summary = (data) =&gt; {\n    // TODO: replace below code with meaningful summary of data.\n  if (!data)\n    return \"No data\";\n  return JSON.stringify(data || {})\n}\n\n{/* Return progress in percentage (0-100) */}\nexport const progress = (data) =&gt; {\n    // TODO: replace below code with percentage of user completion.\n  if (!data)\n    return 0;\n  const totalKeys = 3;\n  const numKeys = Object.values(data).filter(v =&gt; {\n    if (typeof (v) === \"string\" || Array.isArray(v)) {\n      return v.length &gt; 0;\n    } else {\n      return true;\n    }\n  }).length;\n  return Math.round((numKeys / totalKeys) * 100);\n}\n\n{/* Validate data. */}\nexport const validate = (data) =&gt; {\n  // TODO: replace below code with data validation. \n  return progress(data) == 100;\n}\n</code></pre> <p>Developers should implement the methods as defined to provide meaningful summary and track progress of the input block completion. The <code>validate</code> method tells the portal whether the input block data is valid.</p> <p>Note</p> <p>If the input block summary <code>validate</code> function return false, then the portal will not allow report generation until the input block data validate success. If the input block does not require the data to be validated before generating report, then developer should return true for this function.</p>"},{"location":"plugins/widget/MDX_Guide/","title":"MDX Simple Guide","text":"<p>MDX is a superset of markdown that allows developers to use JDX in the markdown content. It allows developers to write Markdown with embedded components through JSX. You can learn more about MDX in the MDX Site.</p> <p>For AI Verify projects, widgets and input blocks use MDX to create dynamic React components that is loaded as part of canvas or user input prompts.</p>"},{"location":"plugins/widget/MDX_Guide/#mdx-props","title":"MDX Props","text":"<p>MDX props is used to pass data from the parent container to the MDX content. The data is accessed through the global props variable. The following sections describe what data is passed to the widget and input block MDX.</p>"},{"location":"plugins/widget/MDX_Guide/#widget-props","title":"Widget Props","text":"<p>Each widget MDX has the following properties:</p> <ul> <li>props.inputBlockData</li> <li>props.result</li> <li>props.properties</li> <li>props.container</li> </ul> <p>Note: For inputBlockData and result properties, developer should handle cases where the result or input block data is not available and handle accordingly.</p> <p>For example, to access the result of an algorithm.</p> <pre><code>export const algo_gid = \"my-algoritm-gid\"\n\n{props.result[algo_gid]?(\n  &lt;&gt;\n    &lt;b&gt;JSON output of algorithm&lt;/b&gt;\n    &lt;div style={{ maxHeight:\"100px\", overflow:\"auto\" }}&gt;{JSON.stringify(props.result[algo_gid])}&lt;/div&gt;\n  &lt;/&gt;\n):(\n  &lt;div&gt;No data&lt;/div&gt;\n)}\n</code></pre> <p>The following example display the width and height of the parent container.</p> <pre><code>&lt;div style={{ widget:props.container.width, backgroundColor:\"olive\", color:\"white\" }}&gt;\n  Container size: width {props.container.width}px, height {props.container.height}px\n&lt;/div&gt;\n</code></pre>"},{"location":"plugins/widget/MDX_Guide/#input-block-props","title":"Input Block Props","text":"<p>Each input block MDX has the following properties:</p> <ul> <li>props.data</li> <li>props.onChangeData</li> </ul>"},{"location":"plugins/widget/MDX_Guide/#markdown","title":"Markdown","text":"<p>MDX supports standard Markdown (see cheatsheet).</p> <p>Some examples of markdown.</p> <p>Italic and bold text with some <code>inline code</code>. * Unordered list 1. Ordered List</p>"},{"location":"plugins/widget/MDX_Guide/#jsx","title":"JSX","text":"<p>JSX provides support for reusable components in MDX.</p> <p>For example, to use JSX markup directly:</p> <pre><code>&lt;div&gt;Hello World&lt;/div&gt;\n</code></pre> <p>To create a JDX component in an MDX:</p> <pre><code>export const HelloWorld = () =&gt; (\n  &lt;div&gt;Hello World again&lt;/div&gt;\n)\n\n&lt;HelloWorld /&gt;\n</code></pre> <p>It is also possible to import another MDX or component file.</p> <p>For example, you can save the above HelloWorld component to a seperate \"helloWorld.mdx\" file and then import it using:</p> <pre><code>import { HelloWorld } from './helloWorld.mdx'\n</code></pre>"},{"location":"plugins/widget/MDX_Guide/#html-form-elements-for-input-block","title":"HTML Form Elements for Input Block","text":"<p>Developers can use HTML form elements to prompt and capture user input. Developers can use <code>props.onChangeData</code> to save the user data. Onchange, the saved data will be available in <code>props.data</code>.</p> <p>Below is an example of a component that displays a simple form and save the form data onChange.</p> <pre><code>&lt;div style={{ display:\"flex\", flexDirection:\"column\", marginBottom:\"10px\" }}&gt;\n  &lt;label htmlFor=\"fname\"&gt;First name:&lt;/label&gt;\n  &lt;input type=\"text\" id=\"fname\" value={props.data[\"fname\"]} onChange={(e)=&gt;props.onChangeData(\"fname\",e.target.value)} /&gt;\n  &lt;label htmlFor=\"lname\"&gt;Last name:&lt;/label&gt;\n  &lt;input type=\"text\" id=\"lname\" value={props.data[\"lname\"]} onChange={(e)=&gt;props.onChangeData(\"lname\",e.target.value)} /&gt;\n  &lt;label htmlFor=\"bio\"&gt;Bio:&lt;/label&gt;\n  &lt;textarea rows=\"4\" style={{ width:\"100%\", resize:\"none\" }} value={props.data[\"bio\"]} onChange={(e)=&gt;props.onChangeData(\"bio\",e.target.value)} /&gt;\n&lt;/div&gt;\n</code></pre>"},{"location":"plugins/widget/MDX_Guide/#ai-verify-shared-library","title":"AI Verify Shared Library","text":"<p>The AI Verify Shared Library provides some shared components that can be imported by MDX. See Shared Library Documentation.</p>"},{"location":"plugins/widget/MDX_Guide/#example-use-of-barcharts","title":"Example use of BarCharts","text":"<p>Below is an example of how to add a BarChart component from the AI Verify Shared Charts Library.</p> <pre><code>import { BarChart } from 'aiverify-shared-library/charts'\n\nexport const data01 = [\n  {\n    name: 'Page A',\n    uv: 4000,\n    pv: 2400,\n    amt: 2400,\n  },\n  {\n    name: 'Page B',\n    uv: 3000,\n    pv: 1398,\n    amt: 2210,\n  },\n  {\n    name: 'Page C',\n    uv: 2000,\n    pv: 9800,\n    amt: 2290,\n  },\n  {\n    name: 'Page D',\n    uv: 2780,\n    pv: 3908,\n    amt: 2000,\n  },\n  {\n    name: 'Page E',\n    uv: 1890,\n    pv: 4800,\n    amt: 2181,\n  },\n  {\n    name: 'Page F',\n    uv: 2390,\n    pv: 3800,\n    amt: 2500,\n  },\n  {\n    name: 'Page G',\n    uv: 3490,\n    pv: 4300,\n    amt: 2100,\n  },\n];\n\n&lt;div style={{ width:props.container.width, height:\"220px\", padding:\"10px\" }}&gt;\n  &lt;BarChart\n    data={data01}\n    xAxisDataKey=\"name\"\n    bars={[{ dataKey:\"uv\" }, { dataKey:\"pv\" }, { dataKey:\"amt\" }]}\n  /&gt;\n&lt;/div&gt;\n</code></pre>"},{"location":"plugins/widget/MDX_Guide/#example-use-of-decision-tree","title":"Example use of Decision Tree","text":"<p>The AI Verify Shared Library DecisionTree allows user to build their own decision tree.</p> <p>You can find an example of Decision Tree Input Block from the Fairness Metrics Toolbox for Classification plugin. An example use of the DecisionTree component can be found in the implementation for the AI Verify Fairness Tree is found under the inputs folder.</p>"},{"location":"plugins/widget/Playground/","title":"Using the Playground","text":"<p>The Playground provides a UI that allows you to view your widgets and input blocks before installing to AI Verify.</p> <pre><code>$ aiverify-plugin playground --help\naiverify-plugin playground\n\nLaunch the plugin playround\n\nOptions:\n  --help       Show help                                                                    [boolean]\n--pluginDir  Path to plugin directory                                       [string] [default: \".\"]\n--port       Playground port to listen on                                  [number] [default: 5000]\n--hostname   Playground hostname to listen on                       [string] [default: \"localhost\"]\n</code></pre> <p>To launch the playground, run the following command under a Plugin directory.</p> <pre><code>aiverify-plugin playground\n</code></pre> <p>Use your browser to navigate to http://localhost:5000. You should now be able to access the playground. To listen on another port besides the default port 5000, use the <code>--port</code> flag. For example to listen on port 8080,</p> <pre><code>$ aiverify-plugin playground --port=8080\nLoading playground..\n&gt; Playground listening at http://localhost:8080\n</code></pre> <p>Now you can access the playground from http://localhost:8080.</p>"},{"location":"plugins/widget/Playground/#playground-landing-page","title":"Playground Landing Page","text":""},{"location":"plugins/widget/Playground/#menu","title":"Menu","text":"<p>The left panel display the plugin meta information as well as the menu bar with list of Widget, Input Block and Algorithm components found under the plugin. You can click on a component to view it.</p>"},{"location":"plugins/widget/Playground/#widgets","title":"Widgets","text":"<p>The widget page center panel displays the widget as it will appears in the Portal canvas. You can update the widget MDX file and then click the Refresh button to visualize your changes. Drag the component handle on the right and bottom of the widget to resize the widget.</p> <p>The Widget Meta tab in the right panel displays the widget meta information defined in <code>&lt;widget cid&gt;.meta.json</code>.</p>"},{"location":"plugins/widget/Playground/#widget-properties","title":"Widget Properties","text":"<p>Click on the Properties tab on the right panel to view the widget properties defined in the widget meta.</p>"},{"location":"plugins/widget/Playground/#input-blocks","title":"Input Blocks","text":"<p>The input block page center panel displays the input block component as it will appears in the Portal inputs. You can update the input block MDX file and then click the Refresh button to visualize your changes.</p> <p>The Input Block Meta tab in the right panel displays the input block meta information defined in <code>&lt;input block cid&gt;.meta.json</code>.</p>"},{"location":"plugins/widget/Playground/#input-block-data-output","title":"Input Block Data Output","text":"<p>Click on the Data Output tab ib tge right panel to view the JSON data that will be saved in the Portal upon changes to the input block data fields.</p>"},{"location":"plugins/widget/Playground/#algorithms","title":"Algorithms","text":"<p>The algorithm page center panel displays algorithm input arguments that will be displayed in the Portal Test Run page. The input arguments are defined in <code>input.schema.json</code>. You can update <code>input.schema.json</code> and then click the Refresh button to visualize the changes.</p> <p>The Algorithm Meta tab in the right panel displays the algorithm meta information defined in <code>algo.meta.json</code>.</p>"},{"location":"plugins/widget/Playground/#input-schema","title":"Input Schema","text":"<p>Click on the Input Schema tab to view the input schema defined for this algorithm.</p>"},{"location":"plugins/widget/Playground/#output-schema","title":"Output Schema","text":"<p>Click on the Output Schema tab to view the output schema defined for this algorithm.</p>"},{"location":"plugins/widget/Plugin/","title":"AI Verify Plugin","text":"<p>The AI Verify plugins allows contributors to developer their own plugins, that can be installed into AI Verify portal and used to extend the functionality of the portal.</p>"},{"location":"plugins/widget/Plugin/#terminology","title":"Terminology","text":"<p>This section defines the terminology used.</p> Term Definition plugin AI Verify plugin that can be installed using the AI Verify portal. component Each AI Verify plugin consists of one or more components and can be used to extend the functionality of the system. The types of components are described in the table below. gid Global Identifier. All plugins requires a unique global identifier that is used to identify the plugin. See Global Identifier (GID). cid Component ID. Unique ID that identifies the component within the plugin. See Component Identifier (CID)"},{"location":"plugins/widget/Plugin/#plugin-structure","title":"Plugin Structure","text":"<p>The diagram below describes the folders and files that may be found under each plugin. </p> <p>Each of the component type folder can contain one or more components.</p> <p>For algorithms, each algorithm has its own subfolder under the algorithms folder named with the algorithm id. For example, algorithmA should have a sub-folder called \"algorithmA\" under the algorithms folder.</p> <p>For widgets, input blocks and templates, each instance of the components should be saved under the component folder; and the filenames of the component should correspond to the component cid. For example, widgetA should have the following files under the widgets folder. * widgetA.meta.json * widgetA.mdx</p>"},{"location":"plugins/widget/Plugin/#ai-verify-components","title":"AI Verify Components","text":"<p>The different components that can be found in a plugin is described in the table below. Please refer to the linked article for more information on the component schemas and required files.</p> Component Type Component Type Folder Description Algorithm algorithms Algorithm components add new test algorithms to the system. Input Block inputs Loaded as a dialog box at the project User Input page ot prompt user to input data Widget widgets Used in canvas to display information to user and printed as part of report. Template templates Project templates that, when installed, can be used at creation of new projects to load a pre-defined canvas"},{"location":"plugins/widget/Plugin/#plugin-package","title":"Plugin Package","text":"<p>The plugin package is a zip file containing the plugin meta file (plugin.meta.json) and at least one components type folder containing at least one component. The file and folder structure of a plugin is described in the plugin structure diagram.</p>"},{"location":"plugins/widget/Plugin/#global-identifier-gid","title":"Global Identifier (GID)","text":"<p>The GID identifies the plugin and MUST be globally unique, i.e. no two plugin should have the same GID. The format of the GID must match the following pattern:</p> <p>^a-zA-Z0-9*$</p> <p>Note that the first character of the GID must be an alphanumeric character. It is recommended to use a tool like UUID Version 4 generator to generate the GID.</p>"},{"location":"plugins/widget/Plugin/#component-identifier-cid","title":"Component Identifier (CID)","text":"<p>The CID identifies a plugin component and MUST be unique within the plugin. The format of the GID must match the follow pattern:</p> <p>^a-zA-Z0-9*$</p>"},{"location":"plugins/widget/Plugin/#plugin-meta-data","title":"Plugin Meta Data","text":"<p>The plugin.meta.json file is required for all plugins. During installation, the Plugin Manager will scan the root plugin folder for the file and validates the file according to the ai-verify.plugin.schema.json schema definition.</p> Propreties Type Required Description gid string, must match pattern <code>^[a-zA-Z0-9][a-zA-Z0-9-._]*$</code> Yes Unique global identifier to identify the plugin. version string Yes Plugin version, should follow Semantic Versioning format. name string Yes Plugin name author string No Author of the plugin description string No Description of the plugin url string No URL to the plugin web page if available"},{"location":"plugins/widget/Plugin/#example","title":"Example","text":"<pre><code>{\n  \"gid\": \"e6402035-7294-4b69-ace1-68a0442f0194\",\n  \"name\": \"Sample Plugin\",\n  \"version\": \"1.0.0\",\n  \"author\": \"Acme Corporation\",\n  \"description\": \"This is a sample plugin\",\n  \"url\": \"https://acme.com/sampleplugin/\"\n}\n</code></pre>"},{"location":"plugins/widget/Shared_Library/","title":"AI Verify Frontend Shared Library","text":""},{"location":"plugins/widget/Shared_Library/#shared-library","title":"Shared Library","text":""},{"location":"plugins/widget/Shared_Library/#ai-verify-shared-library","title":"AI Verify Shared Library","text":"<p>The shared library is found under the <code>aiverify-shared-library</code> folder under the aiverify repository.</p> <p>The Shared Library contains various shared components that can be used by widget developers in the MDX code. </p> <p>The library contains the following packages:</p> <ul> <li>Charts</li> <li>Graph</li> </ul> <p>Further information on the shared components in the packages and their usage can be found in the README of the package.</p>"},{"location":"plugins/widget/Template/","title":"Template","text":"<p>Each input block consists of at least two files located under the templates folder, which follows the following naming convention:</p> <ul> <li>\\&lt;template cid&gt;.meta.json</li> <li>\\&lt;template cid&gt;.data.mdx</li> </ul>"},{"location":"plugins/widget/Template/#template-meta-data","title":"Template Meta Data","text":"<p>During installation, the Plugin Manager will search for and validate the input block meta data according to the schema ai-verify.template.schema.json schema definitions.</p> Propreties Type Required Description cid string, must match pattern <code>^[a-zA-Z0-9][a-zA-Z0-9-._]*$</code> Yes Unique identifier for the template within the plugin. name string Yes Template name. description string No Template description. author string No Template author"},{"location":"plugins/widget/Template/#exporting-a-template-plugin","title":"Exporting a Template Plugin","text":"<p>For now, the easiest way to create a template component is to export the template as plugin at the AI Verify Project page. This will download a zip file that contains a plugin containing the template data. To add the template component to an existing plugin project, simply copy the templates folder in the plugin zip to the target plugin folder. </p>"},{"location":"plugins/widget/Widget/","title":"Widget","text":"<p>Each widget consists of at least two files, a meta file describing the widget and the MDX file for the widget. The files should be located under widgets folder of the plugin root directory, and file names should follow this format:</p> <ul> <li>\\&lt;widget cid&gt;.meta.json</li> <li>\\&lt;widget cid&gt;.mdx</li> </ul> <p>Assuming you have created a widget with cid \"sample-widget\", then there should be the following files under the widgets folder:</p> <ul> <li>sample-widget.meta.json</li> <li>sample-widget.mdx</li> </ul>"},{"location":"plugins/widget/Widget/#widget-meta-data","title":"Widget Meta Data","text":"<p>During installation, the Plugin Manager will search for and validate the widget meta data according to the schema ai-verify.widget.schema.json schema definitions.</p> Propreties Type Required Description cid string, must match pattern <code>^[a-zA-Z0-9][a-zA-Z0-9-._]*$</code> Yes Unique identifier for the widget within the plugin. name string Yes Widget name. description string No Widget description. widgetSize object Yes Describe the widget size in terms of canvas grid units. See Widget Size Object Schema for the schema of the widgetSize object. properties array No List of widget properties. See Widget Property Schema. tags array of string No List of tags for this widget. Used for search and filtering of the widget dependencies array No List of input blocks and/or algorithms that this widget depends on. See Widget Dependency Schema. mockdata array No List of sample data that is provided to the widget in the canvas page. See Widget Mock Data Schema. dynamicHeight boolean No Indicates whether this widget has dynamic height. See Dynamic Height Widget <p>Note: The widget meta data does not contain a gid property as it is automatically inferred and referenced using the format</p> <p>\\&lt;plugin gid&gt;:\\&lt;widget cid&gt;</p>"},{"location":"plugins/widget/Widget/#dynamic-height-widget","title":"Dynamic Height Widget","text":"<p>When the widget's <code>dynamicHeight</code> meta property is set to true, it indicates that the widget has dynamic height. Dynamic height widgets are special widgets that are treated different at the portal:</p> <ul> <li>At the canvas editor page, dynamic height widgets must be placed at the bottom most position on the canvas, meaning there can be no other widgets beneath a dynamic height widget.</li> <li>During report generation, the widget can \"overflow\" beyond the current page. The report generator will automatically insert page breaks.</li> </ul> <p>Dynamic height widget can use CSS <code>break-after</code>, <code>break-before</code> and <code>break-inside</code> properties to specify where the page breaks can or cannot occur.</p>"},{"location":"plugins/widget/Widget/#widget-size-object-schema","title":"Widget Size Object Schema","text":"<p>The widgetSize property defines the minimum and maximum size of the widget. It is defined in the grid units that is used for the project canvas. When the template designer drags a widget onto the canvas, the default size of the widget is the minimum width and height defined.</p> Propreties Type Required Description minW interger, range 1-12 Yes Minimum widget width. minH interger, range 1-36 Yes Minimum widget height. maxW interger, range 1-12 Yes Maximum widget width. maxH interger, range 1-36 Yes Maximum widget height."},{"location":"plugins/widget/Widget/#widget-property-schema","title":"Widget Property Schema","text":"<p>The widget properties allows widget developers to define properties that affects the look and/or behaviour of the widget. Example of properties are color, textual information, etc. Each property should have a default value that is used if the property has no input. The template designers can change the properties of a widget by right clicking the widget in the canvas page to bring up the property dialog. Each property value can be a string input or selected from the canvas Global Properties.</p> Propreties Type Required Description key string Yes Property key. helper string Yes Helper text for the property. default string No Default value for the property."},{"location":"plugins/widget/Widget/#widget-dependency-schema","title":"Widget Dependency Schema","text":"<p>Widget dependencies define the list of input blocks or algorithms that the widget depends on.</p> Propreties Type Required Description cid string Yes CID of the component dependency. gid string No GID of the plugin which the component dependency resides in. Not required if the component dependency resides in the same plugin as this widget version string No Version of the component dependency. If version is not specified, then no version check will be performed <p>The version property is optional. If no version is specified, then the portal dependency check will NOT do version checking. It is recommended to specify the dependency version if referencing a component in other plugins.</p> <p>If the widget defines an input block dependency, the data that user entered in the AI Verify Portal's User Input page can be accessed from the widget MDX through MDX props <code>props.getIBData</code> method.</p> <p>If the widget defines an algorithm dependency, the results that is output by the algorithm will be provided to the widget MDX as MDX props <code>props.getResults</code> method.</p>"},{"location":"plugins/widget/Widget/#widget-mock-data-schema","title":"Widget Mock Data Schema","text":"<p>Widget mock data provides mock data to the widget at the canvas page. If no mock data is provided, then no data will be provided to the widget at canvas page and the widget MDX should handle this condition.</p> Propreties Type Required Description type string, enum [\"Algorithm\", \"InputBlock\"] Yes Type of sample data cid string Yes CID of the component dependency gid string No GID of the plugin which the component dependency resides in. Not required if the component dependency resides in the same plugin as this widget datapath string yes File path containing the mock data in JSON format, e.g. mockdata.json. The file should be located within the widgets folder."},{"location":"plugins/widget/Widget/#example","title":"Example","text":"<pre><code>{\n  \"cid\": \"sample-widget\",\n  \"name\": \"Sample Widget\",\n  \"description\": \"This is a sample widget\",\n  \"tags\": [\"sample\"],\n  \"properties\": [\n    {\n      \"key\": \"title\",\n      \"helper\": \"Enter the widget title to be displayed at the top of the widget\",\n      \"default\": \"\"\n    }\n  ],\n  \"widgetSize\": {\n    \"minW\": 1,\n    \"minH\": 1,\n    \"maxW\": 12,\n    \"maxH\": 36\n  },\n  \"dependencies\": [\n    {\n      \"cid\": \"fairness_metrics_toolbox_for_classification\",\n    },\n    {\n      \"cid\": \"fairness_tree\"\n    }\n  ],\n  \"mockdata\": [\n    {\n      \"type\": \"Algorithm\",\n      \"cid\": \"fairness_metrics_toolbox_for_classification\",\n      \"datapath\": \"fmt.output.sample.json\" \n    },\n    {\n      \"type\": \"InputBlock\",\n      \"cid\": \"fairness_tree\",\n      \"datapath\": \"fairness_tree.sample.json\"\n    }\n  ]\n}\n</code></pre>"},{"location":"plugins/widget/Widget/#widget-mdx","title":"Widget MDX","text":"<p>Each widget must contain a valid MDX that will be rendered as a widget in an AI Verify report. During creation or update of an AI Verify project, the user can drag and drop a widget onto a project canvas, which will be eventually rendered as part of a report.</p> <p>The widget dependencies informs the sytem what are the algorithms and/or input blocks that the widget depends on. The system then determine what are the algorithms and input blocks to run based on the dependency info. </p> <p>The widget MDX are loaded as React components and the component properties are passed and accessed as props global variable. </p>"},{"location":"plugins/widget/Widget/#widget-props","title":"Widget Props","text":"Propreties Type Description inputBlockData object Object containing the user input data saved, accessed by its gid <code>props.inputBlockData[gid]</code>. result object Object containing the output from an algorithm, accessed by its gid <code>props.result[gid]</code>. properties object Object containing the widget properties entered in the canvas page. container object Object containing the widget container information, see Widget Container getContainerObserver(callback) function Function to create an observer to retrieve the the widget container size, see Widget Container Observer getResults(cid, gid=null) function Function to return result of an algorithm identified by cid. If gid of the algorithm is not specified, the function assumes same plugin gid as the widget. getIBData(cid, gid=null) function Function to return data of an input block identified by cid. If gid of the input block is not specified, the function assumes same plugin gid as the widget. getTest(cid, gid=null) function Function to return test result information (if successful), see Test Result Information getArtifactURL(cid, pathname, gid=null) function Returns the URL of the artifact uploaded for this result. meta object Object containing widget meta data. report object Object containing report information, see Report modelAndDatasets object Object containing model and dataset information used to run the test (See Models and Datasets) <p>Example MDX to print out some of the widget props: <pre><code>export const cid = \"some_algo_cid\"\n\n&lt;div&gt;\n  &lt;pre&gt;{JSON.stringify(props.modelAndDatasets,null,2)}&lt;/pre&gt;\n  &lt;pre&gt;{JSON.stringify(props.report,null,2)}&lt;/pre&gt;\n  &lt;pre&gt;{JSON.stringify(props.getTest(cid),null,2)}&lt;/pre&gt;\n  &lt;pre&gt;{JSON.stringify(props.getResults(cid),null,2)}&lt;/pre&gt;\n&lt;/div&gt;\n</code></pre></p>"},{"location":"plugins/widget/Widget/#widget-container-observer","title":"Widget Container Observer","text":"<p>To retrieve the size of the widget container, call the following getContainerObserver function. The callback function passes the container width and height in pixel.</p> <pre><code>props.getContainerObserver((width, height) =&gt; {\n  // Do something with the constainer width and height\n})\n</code></pre>"},{"location":"plugins/widget/Widget/#test-result-information","title":"Test Result Information","text":"Propreties Type Description timeStart string ISO data string of start time of test run timeTaken number Time to complete test in seconds testArguments object Test arguments"},{"location":"plugins/widget/Widget/#report","title":"Report","text":"Propreties Type Description timeStart date Date and time of when the report starts generation. timeTaken number Total time taken (in seconds) to run all the tests and generate report. totalTestTimeTaken number Total time taken (in seconds) to run all the tests."},{"location":"plugins/widget/Widget/#models-and-datasets","title":"Models and Datasets","text":"Propreties Type Description testDataset object Object containing test dataset information, see Dataset Object Schema for information on dataset fields model object Object containing model information groundTruthDataset object Object containing ground truth dataset information, see Dataset Object Schema for information on dataset fields groundTruthColumn string Ground truth feature name"},{"location":"plugins/widget/Widget/#dataset-object-schema","title":"Dataset Object Schema","text":"Propreties Type Description filename string File name of dataset name string Name of dataset size string Size of dataset description string Dataset description type string Dataset type (File, Folder) dataFormat string Dataset data format"},{"location":"plugins/widget/Widget/#ai-model-object-schema","title":"AI Model Object Schema","text":"Propreties Type Description name string Name of model description string model description size string Size of model type string Model access type (File, Folder, Pipeline, API) modelType string Model type (Classification, Regression) modelFormat string Model format"},{"location":"plugins/widget/Widget/#guidelines-for-creating-mdx-files","title":"Guidelines for Creating MDX Files","text":"<p>You can refer to this guideline for additional information in creating MDX files.</p>"},{"location":"stock_plugins/","title":"AI Verify Stock Plugins","text":""},{"location":"stock_plugins/#description","title":"Description","text":"<p>This section documents the various stock plugins packaged in AI Verify.</p>"},{"location":"stock_plugins/#list-of-stock-plugins-in-ai-verify","title":"List of Stock Plugins in AI Verify","text":"<ol> <li>Fairness Metrics Toolbox for Classification</li> <li>Fairness Metrics Toolbox for Regression</li> <li>Robustness Toolbox</li> <li>SHAP</li> <li>Partial Dependent Plot</li> <li>Accumulated Local Effect</li> <li>Image Corruption Algorithms</li> <li>Stock Reports</li> <li>Process Checklist</li> <li>Decorators</li> </ol>"},{"location":"stock_plugins/ale/","title":"Accumulated Local Effect","text":"<p>(aiverify.stock.accumulated-local-effect) [source]</p>"},{"location":"stock_plugins/ale/#description","title":"Description","text":"<p>This plugin explains how each feature and its feature value contribute to the predictions. The results are visualised as line graphs for each feature.</p>"},{"location":"stock_plugins/ale/#plugin-content","title":"Plugin Content","text":"<ul> <li>Algorithms</li> </ul> Name Description Accumulated Local Effect This algorithm explains how each feature and its feature value contribute to the predictions. <ul> <li>Widgets</li> </ul> Name Description Introduction To provide an introduction to Accumulated Local Effect ALE Line Graphs To generate and display ALE values in line graphs for each feature in each class output Recommendation To provide recommendations on explainability"},{"location":"stock_plugins/ale/#using-the-plugin-in-ai-verify","title":"Using the Plugin in AI Verify","text":""},{"location":"stock_plugins/ale/#sample-use-of-the-widgets","title":"Sample use of the widgets","text":""},{"location":"stock_plugins/ale/#more-details","title":"More details","text":"Algorithm input schema  <pre><code>{\n\"title\": \"Algorithm Plugin Input Arguments\",\n\"description\": \"A schema for algorithm plugin input arguments\",\n\"type\": \"object\",\n\"properties\": {\n}\n}\n</code></pre> Algorithm output schema  <pre><code>{\n\"title\": \"Algorithm Plugin Output Arguments\",\n\"description\": \"A schema for algorithm plugin output arguments\",\n\"type\": \"object\",\n\"required\": [\n\"feature_names\",\n\"results\"\n],\n\"minProperties\": 1,\n\"properties\": {\n\"feature_names\": {\n\"type\": \"array\",\n\"description\": \"Array of feature names\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"string\"\n}\n},\n\"results\": {\n\"title\": \"Matrix of feature values (# feature names)\",\n\"description\": \"The results of feature names\",\n\"type\": \"array\",\n\"minItems\": 1,\n\"items\": {\n\"description\": \"Results of indices, ale, and size\",\n\"type\": \"object\",\n\"required\": [\n\"indices\",\n\"ale\",\n\"size\"\n],\n\"minProperties\": 3,\n\"properties\": {\n\"indices\": {\n\"title\": \"Indices\",\n\"type\": \"array\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"number\"\n}\n},\n\"ale\": {\n\"title\": \"ale (# of indices)\",\n\"type\": \"array\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"number\"\n}\n},\n\"size\": {\n\"title\": \"size (# of indices)\",\n\"type\": \"array\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"number\"\n}\n}\n}\n}\n}\n}\n}\n</code></pre>"},{"location":"stock_plugins/decorators/","title":"AI Verify Stock Decorators","text":"<p>(aiverify.stock.decorators) [source]</p>"},{"location":"stock_plugins/decorators/#description","title":"Description","text":"<p>This plugin contains the stock decorators for the AI Verify report.</p>"},{"location":"stock_plugins/decorators/#plugin-content","title":"Plugin Content","text":"<p>Widgets</p> <ul> <li>Divider</li> <li>Header 1</li> <li>Header 2</li> <li>Header 3</li> <li>Header 4</li> <li>Header 5</li> <li>Header 6</li> </ul>"},{"location":"stock_plugins/fmtc/","title":"Fairness Metrics Toolbox for Classification","text":"<p>(aiverify.stock.fairness-metrics-toolbox-for-classification) [source]</p>"},{"location":"stock_plugins/fmtc/#description","title":"Description","text":"<p>The Fairness Metrics Toolbox (FMT) for Classification contains a list of fairness metrics to measure how resources (e.g. opportunities, food, loan, medical help) are allocated among the demographic groups (e.g. married male, married female) given a set of sensitive feature(s) (e.g. gender, marital status). This plugin is developed for classification models.</p>"},{"location":"stock_plugins/fmtc/#plugin-content","title":"Plugin Content","text":"<ul> <li>Algorithms</li> </ul> Name Description Fairness Metrics Toolbox for Classification This algorithm computes a list of fairness metrics to measure how correctly your model predicts among the given set of sensitive features.  Fairness metrics include: False Negative Rate Parity, False Positive Rate Parity, False Discovery Rate Parity, False Omission Rate Parity, True Positive Rate Parity, True Negative Rate Parity, Positive Predictive Value Parity, Negative Predictive Value Parity <ul> <li>Widgets</li> </ul> Name Description Bar Chart (Selected) To generate bar chart(s) for the selected fairness metric(s) from the fairness tree Interpretation (Selected) To provide interpretation for the selected fairness metric(s) from the fairness tree Description (Summary) To provide an introduction to the Fairness Metrics Toolbox for Classification Interpretation (Summary) To provide interpretation and recommendations to the results Table of Definition To provide a table of definitions for all the fairness metrics calculated Fairness Metrics (All) To generate all fairness metrics"},{"location":"stock_plugins/fmtc/#using-the-plugin-in-ai-verify","title":"Using the Plugin in AI Verify","text":"<p>This plugin was mainly designed for tabular datasets, but can also be used on image datasets.</p>"},{"location":"stock_plugins/fmtc/#algorithm-user-inputs","title":"Algorithm User Input(s)","text":"Input Field Description Type Sensitive Feature Name Array of sensitive features names  You may select multiple sensitive features of interest, and as a guide these are usually demographic features <code>array</code> Annotated ground truth path For image datasets: An uploaded dataset containing image file names and the corresponding ground truth label  For tabular datasets: Select the ground truth dataset <code>string</code> Name of column containing image file name For image datasets: Key in the name of the column containing the file names in the annotated ground truth dataset  For tabular datasets: Key in <code>NA</code> <code>string</code>"},{"location":"stock_plugins/fmtc/#algorithm-input-block-fairness-tree","title":"Algorithm Input Block - Fairness Tree","text":"<p>The Fairness Tree helps you to select the most relevant fairness metrics for your use case. Read more on how to use the fairness tree here </p>"},{"location":"stock_plugins/fmtc/#sample-use-of-the-widgets","title":"Sample use of the widgets","text":""},{"location":"stock_plugins/fmtc/#more-details","title":"More details","text":"Algorithm input schema  <pre><code>{\n\"title\": \"Algorithm Plugin Input Arguments\",\n\"description\": \"A schema for algorithm plugin input arguments\",\n\"type\": \"object\",\n\"required\": [\n\"sensitive_feature\", \"annotated_labels_path\",\"file_name_label\"\n],\n\"properties\": {\n\"sensitive_feature\": {\n\"title\": \"Sensitive Feature Names\",\n\"description\": \"Array of Sensitive Feature Names (e.g. Gender)\",\n\"type\": \"array\",\n\"items\": {\n\"type\": \"string\"\n},\n\"minItems\": 1\n},\n\"annotated_labels_path\": {\n\"title\": \"Annotated labels path\",\n\"description\": \"Annotated labels path\",\n\"type\": \"string\",\n\"ui:widget\": \"selectDataset\"\n},\n\"file_name_label\": {\n\"title\": \"Name of column containing image file names\",\n\"description\": \"Key in the name of the column containing the file names in the annotated ground truth dataset\",\n\"type\": \"string\"\n}\n}\n}\n</code></pre> Algorithm output schema  <pre><code>{\n\"title\": \"Algorithm Plugin Output Arguments\",\n\"description\": \"A schema for algorithm plugin output arguments\",\n\"type\": \"object\",\n\"required\": [\n\"sensitive_feature\",\n\"output_classes\",\n\"results\"\n],\n\"properties\": {\n\"sensitive_feature\": {\n\"description\": \"Array of sensitive feature names\",\n\"type\": \"array\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"string\"\n}\n},\n\"output_classes\": {\n\"description\": \"Array of output classes\",\n\"type\": \"array\",\n\"minItems\": 1,\n\"items\": {\n\"type\": [\n\"string\",\n\"number\",\n\"integer\",\n\"boolean\"\n]\n}\n},\n\"results\": {\n\"description\": \"Array of metrics by output classes (# output classes)\",\n\"type\": \"array\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"object\",\n\"description\": \"Dictionary of metric values by group\",\n\"required\": [\n\"True Positive Rate\",\n\"True Negative Rate\",\n\"Positive Predictive Value Parity\",\n\"Negative Predictive Value Parity\",\n\"False Positive Rate\",\n\"False Negative Rate\",\n\"False Discovery Rate\",\n\"False Omission Rate\",\n\"Equal Selection Parity\",\n\"Disparate Impact\"\n],\n\"properties\": {\n\"True Positive Rate\": {\n\"$ref\": \"#/$defs/metric\"\n},\n\"True Negative Rate\": {\n\"$ref\": \"#/$defs/metric\"\n},\n\"Positive Predictive Value Parity\": {\n\"$ref\": \"#/$defs/metric\"\n},\n\"Negative Predictive Value Parity\": {\n\"$ref\": \"#/$defs/metric\"\n},\n\"False Positive Rate\": {\n\"$ref\": \"#/$defs/metric\"\n},\n\"False Negative Rate\": {\n\"$ref\": \"#/$defs/metric\"\n},\n\"False Discovery Rate\": {\n\"$ref\": \"#/$defs/metric\"\n},\n\"False Omission Rate\": {\n\"$ref\": \"#/$defs/metric\"\n},\n\"Equal Selection Parity\": {\n\"$ref\": \"#/$defs/metric2\"\n},\n\"Disparate Impact\": {\n\"$ref\": \"#/$defs/metric2\"\n}\n}\n}\n}\n},\n\"$defs\": {\n\"metric\": {\n\"description\": \"Array of metric values for each group, e.g. [{group:[1,2], metric:0.122},...]\",\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\n\"group\",\n\"metric\"\n],\n\"properties\": {\n\"group\": {\n\"type\": \"array\",\n\"description\": \"Array of group values, one value for each feature, .e.g group: [1,4,7]\"\n},\n\"metric\": {\n\"type\": \"number\"\n}\n}\n},\n\"minItems\": 2\n},\n\"metric2\": {\n\"description\": \"Array of metric values for each group, e.g. [{group:[1,2], metric:0.122},...]\",\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\n\"group\",\n\"metric\"\n],\n\"properties\": {\n\"group\": {\n\"type\": \"array\",\n\"description\": \"Array of group values, one value for each feature, .e.g group: [1,4,7]\"\n},\n\"metric\": {\n\"type\": \"number\"\n}\n}\n},\n\"minItems\": 1\n}\n}\n}\n</code></pre>"},{"location":"stock_plugins/fmtr/","title":"Fairness Metrics Toolbox for Regression","text":"<p>(aiverify.stock.fairness-metrics-toolbox-for-regression) [source]</p>"},{"location":"stock_plugins/fmtr/#description","title":"Description","text":"<p>This plugin computes and displays a list of fairness metrics to measure how correctly your regression model predicts among the given set of sensitive features.</p>"},{"location":"stock_plugins/fmtr/#plugin-content","title":"Plugin Content","text":"<ul> <li>Algorithms</li> </ul> Name Description Fairness Metrics Toolbox for Regression The algorithm computes a list of fairness metrics to measure how correct your model predicts among the given set of sensitive features. <ul> <li>Widgets</li> </ul> Name Description Introduction To provide an introduction to the Fairness Metric Toolbox for Regression Understanding Bar Chart To guide your users on reading the generated bar chart Bar Chart (MAE) To generate the bar chart to show the mean absolute error parity between the subgroups Bar Chart (MSE) To generate the bar chart to show the mean square error parity between the subgroups Bar Chart (R2) To generate the bar chart to show the r2 score parity between the subgroups Interpretation (MAE) To interpret the mean absolute error parity results Interpretation (MSE) To interpret the mean square error parity results Interpretation (R2) To interpret the r2 score parity results Recommendation To provide a recommendation for fairness testing for regression models Table of Definitions To provide a table of definitions"},{"location":"stock_plugins/fmtr/#using-the-plugin-in-ai-verify","title":"Using the Plugin in AI Verify","text":""},{"location":"stock_plugins/fmtr/#algorithm-user-inputs","title":"Algorithm User Input(s)","text":"Input Field Description Type Sensitive Feature Name Array of sensitive features names  You may select multiple sensitive features of interest, and as a guide these are usually demographic features <code>array</code>"},{"location":"stock_plugins/fmtr/#sample-use-of-the-widgets","title":"Sample use of the widgets","text":""},{"location":"stock_plugins/fmtr/#more-details","title":"More details","text":"Algorithm input schema  <pre><code>{\n\"title\": \"Algorithm Plugin Input Arguments\",\n\"description\": \"A schema for algorithm plugin input arguments\",\n\"type\": \"object\",\n\"required\": [\n\"sensitive_feature\"\n],\n\"properties\": {\n\"sensitive_feature\": {\n\"title\": \"Sensitive Feature Names\",\n\"description\": \"Array of Sensitive Feature Names (e.g. Gender)\",\n\"type\": \"array\",\n\"items\": {\n\"type\": \"string\"\n},\n\"minItems\": 1\n}\n}\n}\n</code></pre> Algorithm output schema  <pre><code>{\n\"title\": \"Algorithm Plugin Output Arguments\",\n\"description\": \"A schema for algorithm plugin output arguments\",\n\"type\": \"object\",\n\"required\": [\"results\"],\n\"minProperties\": 1,\n\"properties\": {\n\"results\": {\n\"type\": \"array\",\n\"minItems\": 1,\n\"title\": \"The results Schema\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"mae\": {\n\"type\": \"number\"\n},\n\"r2\": {\n\"type\": [\n\"number\",\n\"null\"\n]\n},\n\"mse\": {\n\"type\": \"number\"\n},\n\"subgroup\": {\n\"type\": \"string\"\n}\n}\n}\n}, \"sensitive_feature\":{\n\"description\":\"Array of sensitive feature names\",\n\"type\":\"array\",\n\"minItems\":1,\n\"items\":{\n\"type\":\"string\"\n}\n}\n}\n}\n</code></pre>"},{"location":"stock_plugins/image_corruption/","title":"Image Corruption Toolbox","text":"<p>(aiverify.stock.image-corruption-toolbox) [source]</p>"},{"location":"stock_plugins/image_corruption/#description","title":"Description","text":"<p>This plugin tests the robustness of AI models to natural corruptions. </p> <p>There are four different broad groups of corruptions that are packaged in this plugin. Each of these broad groups of corruptions also have more specific corruption functions indicated in brackets below:</p> <ul> <li>General (Gaussian, Poisson, Salt and Pepper)</li> <li>Blur (Gaussian, Glass, Defocus, Horizontal Motion, Vertical Motion, Zoom)</li> <li>Digital (Brightness Up and Down, Contrast Up and Down, Saturate Up and Down, Random Perspective, JPEG Compression)</li> <li>Environmental (Snow, Fog, Rain)</li> </ul> <p>The toolbox generates corrupted images based on the uploaded test data at 5 different severity levels for each corruption function. The accuracy of the model is calculated with the new corrupted datasets.</p>"},{"location":"stock_plugins/image_corruption/#plugin-content","title":"Plugin Content","text":"<ul> <li>Algorithms</li> </ul> Name Description Blur Corruptions Algorithm that adds blur corruptions (gaussian, glass, defocus, horizontal motion, vertical motion, zoom) to images across thresholds of interests, and calculates the accuracy of the model Digital Corruptions Algorithm that adds digital corruptions (brightness up and down, contrast up and down, saturate up and down, random perspective, jpeg compression) to images across thresholds of interests, and calculates the accuracy of the model Environment Corruptions Algorithm that adds environmental corruptions (snow, fog, rain) to images across thresholds of interests, and calculates the accuracy of the model General Corruptions Algorithm that adds general corruptions (gaussian, poisson, salt and pepper) to images across thresholds of interests, and calculates the accuracy of the model <ul> <li>Widgets</li> </ul> Name Description Introduction To provide an introduction to the Image Corruption Toolbox Understanding Bar Chart To guide your users on reading the generated bar charts Bar Chart (by corruptions type) To generate bar chart to visualise the accuracy results when blur corruptions are applied <ul><li> Blur corruption samples </li><li> Digital corruption samples </li> <li> Environment corruption samples</li> <li> General corruption samples</li></ul> To generate sample images for the different corruption types Recommendation To provide recommendations for robustness (image corruptions) testing"},{"location":"stock_plugins/image_corruption/#algorithm-details","title":"Algorithm Details","text":"<p>Refer to the README file under each algorithm for more details on the algorithm.</p> <ul> <li>General Corruptions</li> <li>Blur Corruptions</li> <li>Digital Corruptions</li> <li>Environment Corruptions</li> </ul>"},{"location":"stock_plugins/pdp/","title":"Partial Dependence Plot","text":"<p>(aiverify.stock.partial-dependence-plot) [source]</p>"},{"location":"stock_plugins/pdp/#description","title":"Description","text":"<p>This plugin explains how each feature and its feature value contribute to the predictions. The results are visualised as line graphs for each feature.</p>"},{"location":"stock_plugins/pdp/#plugin-content","title":"Plugin Content","text":"<ul> <li>Algorithms</li> </ul> Name Description Partial Dependence Plot A Partial Dependence Plot (PDP) explains how each feature and its feature value contribute to the predictions. <ul> <li>Widgets</li> </ul> Name Description Introduction To provide an introduction to Partial Dependence Plot PDP Line Graphs To generate and display PDP values in line graphs for each feature in each class output Recommendation To provide recommendations on explainability"},{"location":"stock_plugins/pdp/#using-the-plugin-in-ai-verify","title":"Using the Plugin in AI Verify","text":""},{"location":"stock_plugins/pdp/#sample-use-of-the-widgets","title":"Sample use of the widgets","text":""},{"location":"stock_plugins/pdp/#more-details","title":"More details","text":"Algorithm input schema  <pre><code>{\n\"title\": \"Algorithm Plugin Input Arguments\",\n\"description\": \"A schema for algorithm plugin input arguments\",\n\"type\": \"object\",\n\"properties\": {\n}\n}\n</code></pre> Algorithm output schema  <pre><code>{\n\"title\":\"Algorithm Plugin Output Arguments\",\n\"description\":\"A schema for algorithm plugin output arguments\",\n\"type\":\"object\",\n\"required\":[\n\"feature_names\",\n\"results\"\n],\n\"properties\":{\n\"feature_names\":{\n\"type\":\"array\",\n\"description\":\"Array of feature names\",\n\"minItems\":1,\n\"items\":{\n\"type\":\"string\"\n}\n},\n\"output_classes\":{\n\"description\":\"Array of output classes\",\n\"type\":\"array\",\n\"minItems\":1,\n\"items\":{\n\"type\":[\n\"string\",\n\"number\",\n\"integer\",\n\"boolean\"\n]\n}\n},\n\"results\":{\n\"description\":\"Matrix of feature values (# feature names)\",\n\"type\":\"array\",\n\"minItems\":1,\n\"items\":{\n\"description\":\"Matrix of PDP plot data (# output classes)\",\n\"type\":\"array\",\n\"minItems\":1,\n\"items\":{\n\"type\":\"array\",\n\"description\":\"Array of PDP values for each feature value (# feature values)\",\n\"minItems\":1,\n\"items\":{\n\"type\":\"object\",\n\"description\":\"Array of feature and PDP value\",\n\"required\":[\n\"feature_value\",\n\"pdp_value\"\n],\n\"properties\":{\n\"feature_value\":{\n\"type\":\"number\"\n},\n\"pdp_value\":{\n\"type\":\"number\"\n}\n}\n}\n}\n}\n}\n}\n}\n</code></pre>"},{"location":"stock_plugins/process_checklist/","title":"AI Verify Process Checklist","text":"<p>(aiverify.stock.process-checklist) [source]</p>"},{"location":"stock_plugins/process_checklist/#description","title":"Description","text":"<p>Process checklist for AI Verify framework</p>"},{"location":"stock_plugins/process_checklist/#plugin-content","title":"Plugin Content","text":"Name Description Overview Overview of AI Verify testing framework Principle Summary Header Summary header to be displayed before the principle summary Overall Summary Summary of all the processs checklists responses Area Descriptions List the framework areas and provide descriptions Area Header Header and description for each framework area <ul><li>Summary - Accountability</li><li>Summary - Data Governance</li><li>Summary - Explainability</li><li>Summary - Fairness</li><li>Summary - Human Agency &amp; Oversight</li><li>Summary - Inclusive Growth, Societal &amp; Environmental Well-Being</li><li>Summary - Reproducibility</li><li>Summary - Robustness</li><li>Summary - Safety</li><li>Summary - Security</li><li>Summary - Transparency</li></ul> Summary of the process checklist for each of the principles <ul><li>User Responses - Accountability</li><li>User Responses - Data Governance</li><li>User Responses - Explainability</li><li>User Responses - Fairness</li><li>User Responses - Human Agency &amp; Oversight</li><li>User Responses - Inclusive Growth, Societal &amp; Environmental Well-Being</li><li>User Responses - Reproducibility</li><li>User Responses - Robustness</li><li>User Responses - Safety</li><li>User Responses - Security</li><li>User Responses - Transparency</li></ul> List the user responses for the process checklists"},{"location":"stock_plugins/report/","title":"AI Verify Stock Reports","text":"<p>(aiverify.stock.reports) [source]</p>"},{"location":"stock_plugins/report/#description","title":"Description","text":"<p>Stock reports for AI Verify</p>"},{"location":"stock_plugins/report/#plugin-content","title":"Plugin Content","text":"<ul> <li>Templates</li> </ul> Name Description AI Verify Summary Report for Classification Model 0.9.0 Template AI Verify summary report for classification model <ul> <li>Widgets</li> </ul> Name Description AIV Introduction Introduction to AI Verify Main Cover Page Main cover page for the reports Section Cover Page For decorating the cover page of a section Global Explainability Introduction Explains what is global explainability Explainability Testing Introduction Explains what is the explainability testing Fairness Testing Introduction Explains what is the fairness testing Robustness Testing Introduction Explains what is the robustness testing Page Divider Custom divider for report Page Title 1 Standard page title 1 Page Title 2 Standard page title 2 Page Title 3 Standard page title 3 Report Summary Report summary Technical Tests Summary Status information on technical test results Use Case And Model Tested Describe use case and model tested"},{"location":"stock_plugins/robustness_toolbox/","title":"Robustness Toolbox","text":"<p>(aiverify.stock.robustness-toolbox) [source]</p>"},{"location":"stock_plugins/robustness_toolbox/#description","title":"Description","text":"<p>This plugin generates a perturbed dataset using boundary attack algorithm on the test dataset. </p> <p>Boundary Attack is an attack that starts by adding a large amount of noise to a data point intentionally to cause a model it misclassified by the model. This plugin uses Salt-and-pepper noise to create the large amount of noise. Then, it will reduce the amount of noise added while maintaining misclassification. This algorithm does not depend on the underlying model's architecture or parameters.</p> <p>This algorithm is developed for image dataset but can also be used to create noise on tabular dataset. However, it is to note that testing on tabular dataset may warrant caution when interpreting the results as this is not well-tested.</p>"},{"location":"stock_plugins/robustness_toolbox/#plugin-content","title":"Plugin Content","text":"<ul> <li>Algorithms</li> </ul> Name Description Robustness Toolbox This algorithm generates a perturbed dataset using boundary attack algorithm on the test dataset <ul> <li>Widgets</li> </ul> Name Description Description (Summary) To provide introduction, interpretation and recommendations for robustness testing Bar Chart (Accuracy) To generate and display a bar chart of the orignal and perturbed dataset with interpretation of the results Description (Technical) To provide introduction, bar chart, interpretation and recommendations for robustness testing with technical details"},{"location":"stock_plugins/robustness_toolbox/#using-the-plugin-in-ai-verify","title":"Using the Plugin in AI Verify","text":"<p>This plugin was mainly designed for image datasets, but can also be used on tabular datasets.</p>"},{"location":"stock_plugins/robustness_toolbox/#algorithm-user-inputs","title":"Algorithm User Input(s)","text":"Input Field Description Type Annotated ground truth path For image datasets: An uploaded dataset containing image file names and the corresponding ground truth label  For tabular datasets: Select the ground truth dataset <code>string</code> Name of column containing image file name For image datasets: Key in the name of the column containing the file names in the annotated ground truth dataset  For tabular datasets: Key in <code>NA</code> <code>string</code>"},{"location":"stock_plugins/robustness_toolbox/#sample-use-of-the-widgets","title":"Sample use of the widgets","text":""},{"location":"stock_plugins/robustness_toolbox/#more-details","title":"More details","text":"Algorithm input schema  <pre><code>{\n\"title\": \"Algorithm Plugin Input Arguments\",\n\"description\": \"A schema for algorithm plugin input arguments\",\n\"type\": \"object\",\n\"required\": [\n],\n\"properties\": {\n\"annotated_ground_truth_path\": {\n\"title\": \"Annotated ground truth path\",\n\"description\": \"Annotated ground truth path\",\n\"type\": \"string\",\n\"ui:widget\": \"selectDataset\"\n},\n\"file_name_label\": {\n\"title\": \"Name of column containing image file names\",\n\"description\": \"Key in the name of the column containing the file names in the annotated ground truth dataset\",\n\"type\": \"string\"\n}\n}\n}\n</code></pre> Algorithm output schema  <pre><code>{\n\"title\": \"Algorithm Plugin Output Arguments\",\n\"description\": \"A schema for algorithm plugin output arguments\",\n\"type\": \"object\",\n\"required\": [\"results\"],\n\"minProperties\": 1,\n\"properties\": {\n\"results\": {\n\"description\": \"Algorithm Output\",\n\"type\": \"object\",\n\"required\": [\"num_of_perturbed_samples\", \"org_performance\", \"perturbed_performance\", \"num_of_failed_perturbed_samples\"],\n\"properties\": {\n\"num_of_perturbed_samples\": {\n\"description\": \"Number of final perturbed samples\",\n\"type\": \"number\"\n},\n\"original\": {\n\"description\": \"Performance for Original Dataset\",\n\"type\": \"number\"\n},\n\"adversarial\": {\n\"description\": \"Performance for Perturbed Dataset \",\n\"type\": \"number\"\n},\n\"num_of_failed_perturbed_samples\": {\n\"description\": \"Number of samples that failed to generate perturbed samples\",\n\"type\": \"number\"\n}\n}\n}\n}\n}\n</code></pre>"},{"location":"stock_plugins/shap/","title":"SHAP Toolbox","text":"<p>(aiverify.stock.shap-toolbox) [source]</p>"},{"location":"stock_plugins/shap/#description","title":"Description","text":"<p>This plugin explains how your features affect your overall predictions by using Shapley Values.</p>"},{"location":"stock_plugins/shap/#plugin-content","title":"Plugin Content","text":"<ul> <li>Algorithms</li> </ul> Name Description SHAP Toolbox SHAP (SHapley Additive exPlanations) is a game theoretic approach to explain the output of any machine learning model. <ul> <li>Widgets</li> </ul> Name Description Introduction To provide an introduction to SHAP Understanding Bar Chart To guide your users on reading the generated bar chart Bar Chart (Summary) To generate bar chart, interpretation and recommendations for explainability testing Bar Chart (Technical) To display the average SHAP values using a bar chart Recommendations To provide a recommendation for explainability testing"},{"location":"stock_plugins/shap/#using-the-plugin-in-ai-verify","title":"Using the Plugin in AI Verify","text":""},{"location":"stock_plugins/shap/#algorithm-user-inputs","title":"Algorithm User Input(s)","text":"Input Field Description Type Type of explainability Options: [global (default), local]. Global explainability explains overall dataset. Local explainability explains a random data point. <code>string</code> Path of the background data Background data path <code>string</code> Size of the background Background samples (eg. 25) <code>int</code> Size of the test dataset Data Samples (eg. 25) <code>int</code>"},{"location":"stock_plugins/shap/#sample-use-of-the-widgets","title":"Sample use of the widgets","text":""},{"location":"stock_plugins/shap/#more-details","title":"More details","text":"Algorithm input schema  <pre><code>{\n\"title\": \"Algorithm Plugin Input Arguments\",\n\"description\": \"A schema for algorithm plugin input arguments\",\n\"type\": \"object\",\n\"required\": [\n\"explain_type\",\n\"background_path\",\n\"background_samples\",\n\"data_samples\"\n],\n\"properties\": {\n\"explain_type\": {\n\"title\": \"Type of Explainability\",\n\"description\": \"Options: [global (default), local]. Global explainability explains overall dataset. Local explinability explains a random data point.\",\n\"type\": \"string\",\n\"default\": \"global\",\n\"enum\": [\n\"global\",\n\"local\"\n]\n},\n\"background_path\": {\n\"title\": \"Path of the Background Path\",\n\"description\": \"Background data path\",\n\"type\": \"string\",\n\"ui:widget\": \"selectDataset\"\n},\n\"background_samples\": {\n\"title\": \"Size of the Background\",\n\"description\": \"Background Samples (e.g. 25)\",\n\"type\": \"number\"\n},\n\"data_samples\": {\n\"title\": \"Size of the Test Dataset\",\n\"description\": \"Data Samples (e.g. 25)\",\n\"type\": \"number\"\n}\n}\n}\n</code></pre> Algorithm output schema  <pre><code>{\n\"title\": \"Algorithm Plugin Output Arguments\",\n\"description\": \"A schema for algorithm plugin output arguments\",\n\"type\": \"object\",\n\"required\": [\n\"feature_names\",\n\"results\"\n],\n\"properties\": {\n\"feature_names\": {\n\"type\": \"array\",\n\"description\": \"Array of feature names\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"string\"\n}\n},\n\"results\": {\n\"description\": \"Matrix of feature values (# feature names)\",\n\"type\": \"object\",\n\"required\": [\n\"num_local_classes\",\n\"local\",\n\"single_explainer_values\",\n\"single_shap_values\",\n\"global_shap_values\",\n\"global_samples\",\n\"num_global_classes\",\n\"global\"\n],\n\"properties\": {\n\"num_local_classes\": {\n\"description\": \"Number of local classes\",\n\"type\": \"number\"\n},\n\"local\": {\n\"description\": \"# of local classes\",\n\"type\": \"array\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"array\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"array\",\n\"description\": \"class values\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"number\"\n}\n}\n}\n},\n\"single_explainer_values\": {\n\"description\": \"array of single explainer values\",\n\"type\": \"array\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"number\"\n}\n},\n\"single_shap_values\": {\n\"description\": \"array of single shap values\",\n\"type\": \"array\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"array\",\n\"description\": \"class values\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"number\"\n}\n}\n},\n\"global_shap_values\": {\n\"description\": \"global shap values\",\n\"type\": \"array\",\n\"items\": {\n\"type\": \"array\",\n\"description\": \"Matrix of SHAP values (# samples x # features)\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"array\",\n\"description\": \"Array of SHAP values for each feature\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"number\"\n}\n}\n}\n},\n\"global_samples\": {\n\"description\": \"Matrix of feature values (# samples x # features)\",\n\"type\": \"array\",\n\"items\": {\n\"type\": \"array\",\n\"description\": \"Array of sample values for each feature\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"number\"\n}\n}\n},\n\"num_global_classes\": {\n\"description\": \"Number of global classes\",\n\"type\": \"number\"\n},\n\"global\": {\n\"description\": \"# of global classes\",\n\"type\": \"array\",\n\"items\": {\n\"type\": \"array\",\n\"minItems\": 1,\n\"items\": {\n\"type\": \"number\"\n}\n}\n}\n}\n}\n}\n}\n</code></pre>"}]}